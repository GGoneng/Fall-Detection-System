{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79f41ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------------\n",
    "# 파일명       : Fall_Detection.ipynb\n",
    "# 설명         : 스켈레톤 데이터를 가지고 낙상 감지 모델 학습\n",
    "# 작성자       : 이민하\n",
    "# 작성일       : 2025-05-04\n",
    "# \n",
    "# 사용 모듈    :\n",
    "# - pandas                           # 데이터프레임 기반 데이터 처리\n",
    "# - numpy                            # 수치 계산 및 배열 연산\n",
    "# - os                               # 파일 및 경로 관리\n",
    "# - sklearn.model_selection          # 학습/검증용 데이터 분할\n",
    "# - torch, torch.nn, F               # PyTorch 모델 구축 및 연산\n",
    "# - torch.optim, lr_scheduler        # 최적화 및 학습률 조정\n",
    "# - torch.utils.data                 # 데이터셋 및 데이터로더 처리\n",
    "# - torchmetrics.classification      # 분류 모델 평가 지표 계산\n",
    "\n",
    "# -----------------------------------------------------------------------------------\n",
    "# >> 주요 기능\n",
    "# - 스켈레톤 데이터를 RNN 모델 종류를 통해 낙상인지 아닌지 시계열 분석\n",
    "#\n",
    "# >> 업데이트 내역\n",
    "# [2025-05-04] 60fps 시퀀스 데이터 학습 (LSTM)\n",
    "# [2025-05-06] 30fps 시퀀스 데이터 학습 (LSTM)\n",
    "# [2025-05-10] 10fps 시퀀스 데이터 학습 (LSTM)\n",
    "# [2025-05-12] GRU 모델로 변경, 데이터 증강\n",
    "# [2025-05-22] 하이퍼파라미터 최종 튜닝\n",
    "# -----------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486a1992",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PNC\\anaconda3\\envs\\Project_38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임 기반 데이터 처리\n",
    "import pandas as pd\n",
    "\n",
    "# 수치 계산 및 배열 연산\n",
    "import numpy as np\n",
    "\n",
    "# 파일 및 경로 관리\n",
    "import os\n",
    "\n",
    "# 학습/검증용 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# PyTorch 모델 구축 및 연산\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 최적화 및 학습률 조정\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "# 데이터셋 및 데이터로더 처리\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 분류 모델 평가 지표 계산\n",
    "from torchmetrics.classification import BinaryF1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ef92b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 및 라벨 경로 설정\n",
    "DATA_PATH = \"./10fps_merged_data(no interpolation).csv\"\n",
    "LABEL_PATH = \"./Label.csv\"\n",
    "\n",
    "# 데이터 및 라벨 CSV 파일 -> DataFrame 변환\n",
    "data_df = pd.read_csv(DATA_PATH)\n",
    "label_df = pd.read_csv(LABEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e511c393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   frame  landmark_id         x         y         z  source_index\n",
      "0    1.0          0.0  0.432988  0.559980 -0.354303             0\n",
      "1    1.0         11.0  0.465422  0.526178 -0.257993             0\n",
      "2    1.0         12.0  0.408942  0.558263 -0.288992             0\n",
      "3    1.0         13.0  0.474997  0.550322 -0.326235             0\n",
      "4    1.0         14.0  0.391634  0.598874 -0.350726             0\n",
      "\n",
      "\n",
      "   source_index  label\n",
      "0             0      0\n",
      "1             1      0\n",
      "2             2      0\n",
      "3             3      0\n",
      "4             4      0\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인 \n",
    "print(data_df.head())\n",
    "print()\n",
    "print()\n",
    "print(label_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcb3bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source_index\n",
       "2652    3003\n",
       "2655    2899\n",
       "2653    2782\n",
       "2651    2366\n",
       "2648    2314\n",
       "        ... \n",
       "1464    1300\n",
       "1465    1300\n",
       "1466    1300\n",
       "1467    1300\n",
       "4271    1300\n",
       "Name: count, Length: 3781, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 분포 확인\n",
    "data_df[\"source_index\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7100ca39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source_index\n",
       "0.0       1300\n",
       "2840.0    1300\n",
       "2826.0    1300\n",
       "2827.0    1300\n",
       "2828.0    1300\n",
       "          ... \n",
       "1451.0    1300\n",
       "1452.0    1300\n",
       "1453.0    1300\n",
       "1454.0    1300\n",
       "4271.0    1300\n",
       "Name: count, Length: 3781, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 형태 맞추기\n",
    "val = data_df[\"source_index\"].value_counts().values\n",
    "idx = data_df[\"source_index\"].value_counts().index\n",
    "\n",
    "# 13개의 관절을 10fps로 10초짜리 영상에서 추출하므로 13 * 10 * 10 = 1300\n",
    "for i, num in enumerate(val):\n",
    "    if num > 1300:\n",
    "        data_df[data_df[\"source_index\"] == idx[i]] = data_df[data_df[\"source_index\"] == idx[i]][:1300]\n",
    "\n",
    "data_df[\"source_index\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68db4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 제거 (아예 추출이 안된 데이터 제거)\n",
    "data_df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb121711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정렬\n",
    "df = data_df.sort_values(by=[\"source_index\", \"frame\"])\n",
    "\n",
    "# 좌표(x, y, z) 별로 pivot\n",
    "df_pivot = df.pivot(index=[\"frame\", \"source_index\"], columns=\"landmark_id\", values=[\"x\", \"y\", \"z\"])\n",
    "\n",
    "# 다중 인덱스 컬럼 -> 단일 문자열 변환 (예: ('x', 11) -> 'x_11')\n",
    "df_pivot.columns = [f\"{coord}_{int(lid)}\" for coord, lid in df_pivot.columns]\n",
    "\n",
    "# 인덱스 복구 및 정렬\n",
    "df_pivot.reset_index(inplace=True)\n",
    "df_pivot = df_pivot.sort_values(by=[\"source_index\", \"frame\"]).reset_index(drop=True)\n",
    "\n",
    "# 결과 CSV파일로 저장\n",
    "df_pivot.to_csv(\"10fps_reshaped_data(no interpolation).csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ce8997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변형시킨 데이터 불러오기\n",
    "data_df = pd.read_csv(\"10fps_reshaped_data(no interpolation).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "996355c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source_index\n",
       "0.0       100\n",
       "2840.0    100\n",
       "2826.0    100\n",
       "2827.0    100\n",
       "2828.0    100\n",
       "         ... \n",
       "1451.0    100\n",
       "1452.0    100\n",
       "1453.0    100\n",
       "1454.0    100\n",
       "4271.0    100\n",
       "Name: count, Length: 3781, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[\"source_index\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1835ed25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame</th>\n",
       "      <th>source_index</th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_11</th>\n",
       "      <th>x_12</th>\n",
       "      <th>x_13</th>\n",
       "      <th>x_14</th>\n",
       "      <th>x_15</th>\n",
       "      <th>x_16</th>\n",
       "      <th>x_23</th>\n",
       "      <th>...</th>\n",
       "      <th>z_13</th>\n",
       "      <th>z_14</th>\n",
       "      <th>z_15</th>\n",
       "      <th>z_16</th>\n",
       "      <th>z_23</th>\n",
       "      <th>z_24</th>\n",
       "      <th>z_25</th>\n",
       "      <th>z_26</th>\n",
       "      <th>z_29</th>\n",
       "      <th>z_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.432988</td>\n",
       "      <td>0.465422</td>\n",
       "      <td>0.408942</td>\n",
       "      <td>0.474997</td>\n",
       "      <td>0.391634</td>\n",
       "      <td>0.438641</td>\n",
       "      <td>0.427603</td>\n",
       "      <td>0.450574</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326235</td>\n",
       "      <td>-0.350726</td>\n",
       "      <td>-0.429115</td>\n",
       "      <td>-0.415761</td>\n",
       "      <td>0.009984</td>\n",
       "      <td>-0.010148</td>\n",
       "      <td>0.093614</td>\n",
       "      <td>0.096314</td>\n",
       "      <td>0.285863</td>\n",
       "      <td>0.288855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.432988</td>\n",
       "      <td>0.465422</td>\n",
       "      <td>0.408942</td>\n",
       "      <td>0.474997</td>\n",
       "      <td>0.391634</td>\n",
       "      <td>0.438641</td>\n",
       "      <td>0.427603</td>\n",
       "      <td>0.450574</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326235</td>\n",
       "      <td>-0.350726</td>\n",
       "      <td>-0.429115</td>\n",
       "      <td>-0.415761</td>\n",
       "      <td>0.009984</td>\n",
       "      <td>-0.010148</td>\n",
       "      <td>0.093614</td>\n",
       "      <td>0.096314</td>\n",
       "      <td>0.285863</td>\n",
       "      <td>0.288855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.432988</td>\n",
       "      <td>0.465422</td>\n",
       "      <td>0.408942</td>\n",
       "      <td>0.474997</td>\n",
       "      <td>0.391634</td>\n",
       "      <td>0.438641</td>\n",
       "      <td>0.427603</td>\n",
       "      <td>0.450574</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326235</td>\n",
       "      <td>-0.350726</td>\n",
       "      <td>-0.429115</td>\n",
       "      <td>-0.415761</td>\n",
       "      <td>0.009984</td>\n",
       "      <td>-0.010148</td>\n",
       "      <td>0.093614</td>\n",
       "      <td>0.096314</td>\n",
       "      <td>0.285863</td>\n",
       "      <td>0.288855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437716</td>\n",
       "      <td>0.465444</td>\n",
       "      <td>0.413786</td>\n",
       "      <td>0.473494</td>\n",
       "      <td>0.396775</td>\n",
       "      <td>0.440072</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>0.449910</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.306374</td>\n",
       "      <td>-0.344488</td>\n",
       "      <td>-0.399087</td>\n",
       "      <td>-0.399243</td>\n",
       "      <td>0.013423</td>\n",
       "      <td>-0.013590</td>\n",
       "      <td>0.110032</td>\n",
       "      <td>0.094801</td>\n",
       "      <td>0.306888</td>\n",
       "      <td>0.294059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.442443</td>\n",
       "      <td>0.465467</td>\n",
       "      <td>0.418630</td>\n",
       "      <td>0.471991</td>\n",
       "      <td>0.401916</td>\n",
       "      <td>0.441504</td>\n",
       "      <td>0.437306</td>\n",
       "      <td>0.449246</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286514</td>\n",
       "      <td>-0.338250</td>\n",
       "      <td>-0.369060</td>\n",
       "      <td>-0.382725</td>\n",
       "      <td>0.016862</td>\n",
       "      <td>-0.017031</td>\n",
       "      <td>0.126450</td>\n",
       "      <td>0.093288</td>\n",
       "      <td>0.327914</td>\n",
       "      <td>0.299262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   frame  source_index       x_0      x_11      x_12      x_13      x_14  \\\n",
       "0    1.0           0.0  0.432988  0.465422  0.408942  0.474997  0.391634   \n",
       "1    4.0           0.0  0.432988  0.465422  0.408942  0.474997  0.391634   \n",
       "2    7.0           0.0  0.432988  0.465422  0.408942  0.474997  0.391634   \n",
       "3   10.0           0.0  0.437716  0.465444  0.413786  0.473494  0.396775   \n",
       "4   13.0           0.0  0.442443  0.465467  0.418630  0.471991  0.401916   \n",
       "\n",
       "       x_15      x_16      x_23  ...      z_13      z_14      z_15      z_16  \\\n",
       "0  0.438641  0.427603  0.450574  ... -0.326235 -0.350726 -0.429115 -0.415761   \n",
       "1  0.438641  0.427603  0.450574  ... -0.326235 -0.350726 -0.429115 -0.415761   \n",
       "2  0.438641  0.427603  0.450574  ... -0.326235 -0.350726 -0.429115 -0.415761   \n",
       "3  0.440072  0.432454  0.449910  ... -0.306374 -0.344488 -0.399087 -0.399243   \n",
       "4  0.441504  0.437306  0.449246  ... -0.286514 -0.338250 -0.369060 -0.382725   \n",
       "\n",
       "       z_23      z_24      z_25      z_26      z_29      z_30  \n",
       "0  0.009984 -0.010148  0.093614  0.096314  0.285863  0.288855  \n",
       "1  0.009984 -0.010148  0.093614  0.096314  0.285863  0.288855  \n",
       "2  0.009984 -0.010148  0.093614  0.096314  0.285863  0.288855  \n",
       "3  0.013423 -0.013590  0.110032  0.094801  0.306888  0.294059  \n",
       "4  0.016862 -0.017031  0.126450  0.093288  0.327914  0.299262  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd275ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 설정\n",
    "X_list = []\n",
    "\n",
    "for i in data_df[\"source_index\"].unique():\n",
    "    X_list.append(np.array(data_df[data_df[\"source_index\"] == i].drop([\"source_index\"], axis = 1)))\n",
    "\n",
    "X_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcd64ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target 설정\n",
    "y_list = list(label_df[\"label\"])\n",
    "\n",
    "y_list[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5338a4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3781 3781\n"
     ]
    }
   ],
   "source": [
    "print(len(X_list), len(y_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59090dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, Test 데이터 나누기 (Test Size = 0.2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_list, y_list, \n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 42,\n",
    "                                                    stratify = y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0f81e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3024"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dbb855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 연산을 위한 데이터셋\n",
    "class DetectDataset(Dataset):\n",
    "    def __init__(self, feature, target):\n",
    "        self.feature = feature\n",
    "        self.target = target\n",
    "        self.n_rows = len(self.feature)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_rows\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        featureTS = torch.tensor(self.feature[index], dtype = torch.float32)\n",
    "        targetTS = torch.tensor([self.target[index]], dtype = torch.float32)\n",
    "\n",
    "        return featureTS, targetTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e45caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Size 설정\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# 데이터셋, 데이터로더 변환\n",
    "trainDS = DetectDataset(X_train, y_train)\n",
    "trainDL = DataLoader(trainDS, batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b670a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 낙상 감지 모델\n",
    "# 시퀀스 데이터에 강력한 RNN 계열 모델 사용\n",
    "# LSTM 모델 -> GRU 모델 (라즈베리파이 경량화를 위해 변경)\n",
    "class FallDetectModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, n_layers, \n",
    "                 dropout, bidirectional):\n",
    "        super().__init__()\n",
    "\n",
    "        # GRU 모델\n",
    "        self.model = nn.GRU(\n",
    "            input_size = input_size,\n",
    "            hidden_size = hidden_dim,\n",
    "            num_layers = n_layers,\n",
    "            dropout = dropout,\n",
    "            bidirectional = bidirectional,\n",
    "            batch_first = True\n",
    "        )\n",
    "\n",
    "        # 출력층\n",
    "        # 양방향 LSTM (시퀀스 데이터에서 더 많은 정보 추출 가능)\n",
    "        if bidirectional:\n",
    "            self.output = nn.Linear(hidden_dim * 2 , 1)\n",
    "        \n",
    "        else:\n",
    "            self.output = nn.Linear(hidden_dim, 1)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        output, _ = self.model(inputs)\n",
    "        # 마지막 hidden state 선택\n",
    "        output = output[:, -1, :]\n",
    "        result = self.output(output)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d589e072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 파라미터 설정\n",
    "EPOCH = 1000\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "LR = 0.001\n",
    "\n",
    "# 모델 파라미터 설정\n",
    "input_size = 40\n",
    "hidden_dim = 64\n",
    "n_layers = 2\n",
    "dropout = 0.2\n",
    "bidirectional = True\n",
    "\n",
    "# 모델 생성\n",
    "fall_detect_model = FallDetectModel(input_size = input_size, \n",
    "                                    hidden_dim = hidden_dim,\n",
    "                                    n_layers = n_layers,\n",
    "                                    dropout = dropout,\n",
    "                                    bidirectional = bidirectional).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5589e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FallDetectModel(\n",
       "  (model): GRU(40, 64, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (output): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 확인\n",
    "fall_detect_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd61e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실, 평가 함수 생성\n",
    "F1score = BinaryF1Score().to(DEVICE)\n",
    "BCELoss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 옵티마이저 생성\n",
    "optimizer = optim.Adam(fall_detect_model.parameters(), lr = LR)\n",
    "\n",
    "# Learning Rate Scheduler 생성\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode = \"max\", patience = 10, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cbf9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 Test 함수\n",
    "def testing(model, feature, target):\n",
    "    # Pytorch 학습을 위해 데이터프레임 -> 텐서 전환\n",
    "    featureTS = torch.FloatTensor(feature).to(DEVICE)\n",
    "    targetTS = torch.FloatTensor(target).to(DEVICE)\n",
    "\n",
    "    # 데이터 형태 맞춤    \n",
    "    targetTS = targetTS.unsqueeze(1)\n",
    "\n",
    "    # Dropout, BatchNorm 등 가중치 규제 비활성화\n",
    "    model.eval()\n",
    "\n",
    "    # 평가를 위해 역전파 계산 X\n",
    "    with torch.no_grad():\n",
    "        pre_val = model(featureTS)\n",
    "        loss_val = BCELoss(pre_val, targetTS)\n",
    "\n",
    "        # 분류 문제이므로 sigmoid 활성화 함수 + 이진 분류 결과로 변경\n",
    "        probs = torch.sigmoid(pre_val)\n",
    "        preds = (probs > 0.5).int()\n",
    "\n",
    "        score_val = F1score(preds, targetTS.int())\n",
    " \n",
    "\n",
    "    return loss_val, score_val, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312a64ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 Train 함수\n",
    "def training(model, trainDL, X_test, y_test):\n",
    "    \n",
    "    # 가중치 파일 저장 위치 정의\n",
    "    SAVE_PATH = './saved_models/'\n",
    "    os.makedirs(SAVE_PATH, exist_ok = True)\n",
    "\n",
    "    # Early Stopping을 위한 변수\n",
    "    BREAK_CNT_SCORE = 0\n",
    "    LIMIT_VALUE = 200\n",
    "\n",
    "    # Loss, Score 로그를 담을 리스트\n",
    "    BCE_LOSS_HISTORY, SCORE_HISTORY = [[], []], [[], []]\n",
    "\n",
    "    for epoch in range(1, EPOCH + 1):\n",
    "        model.train()\n",
    "        SAVE_WEIGHT = os.path.join(SAVE_PATH, f\"model_weights_{epoch}.pth\")\n",
    "\n",
    "        bce_loss_total, score_total = 0, 0\n",
    "\n",
    "        # Train DataLoader에 저장된 Feature, Target 텐서로 학습 진행\n",
    "        for featureTS, targetTS in trainDL:\n",
    "            # GPU 환경으로 데이터 이동\n",
    "            featureTS = featureTS.to(DEVICE)\n",
    "            targetTS = targetTS.to(DEVICE)\n",
    "            \n",
    "            # 결과 추론\n",
    "            pre_val = model(featureTS)\n",
    "\n",
    "            # 추론값으로 Loss값 계산\n",
    "            bce_loss = BCELoss(pre_val, targetTS)\n",
    "            \n",
    "            # 활성화 함수 + 이진 분류 결과로 변경\n",
    "            probs = torch.sigmoid(pre_val)\n",
    "            preds = (probs > 0.5).int()\n",
    "\n",
    "            # F1 Score 확인 (precision과 recall의 조화평균)\n",
    "            score = F1score(preds, targetTS)\n",
    "\n",
    "            bce_loss_total += bce_loss.item()\n",
    "            score_total += score.item()\n",
    "\n",
    "            # 이전 gradient 초기화\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 역전파로 gradient 계산\n",
    "            bce_loss.backward()\n",
    "\n",
    "            # 계산된 gradient로 가중치 업데이트\n",
    "            optimizer.step()\n",
    "\n",
    "        # Test Loss, Score, 예측값 계산\n",
    "        test_bce_loss, test_score, test_preds = testing(model, X_test, y_test)\n",
    "        \n",
    "        BCE_LOSS_HISTORY[0].append(bce_loss_total / len(trainDL))\n",
    "        SCORE_HISTORY[0].append(score_total / len(trainDL))\n",
    "\n",
    "        BCE_LOSS_HISTORY[1].append(test_bce_loss)\n",
    "        SCORE_HISTORY[1].append(test_score)\n",
    "\n",
    "        print(f\"[{epoch} / {EPOCH}]\\n - TRAIN BCE LOSS : {BCE_LOSS_HISTORY[0][-1]}\")\n",
    "        print(f\"- TRAIN F1 SCORE : {SCORE_HISTORY[0][-1]}\")\n",
    "\n",
    "        print(f\"\\n - TEST BCE LOSS : {BCE_LOSS_HISTORY[1][-1]}\")\n",
    "        print(f\"- TEST F1 SCORE : {SCORE_HISTORY[1][-1]}\")\n",
    "\n",
    "        # Test Score 결과로 스케줄러 업데이트\n",
    "        scheduler.step(test_score)\n",
    "\n",
    "        # Early Stopping 구현\n",
    "        if len(SCORE_HISTORY[1]) >= 2:\n",
    "            if SCORE_HISTORY[1][-1] <= SCORE_HISTORY[1][-2]: BREAK_CNT_SCORE += 1\n",
    "\n",
    "        if len(SCORE_HISTORY[1]) == 1:\n",
    "            torch.save(model.state_dict(), SAVE_WEIGHT)\n",
    "        \n",
    "        else:\n",
    "            if SCORE_HISTORY[1][-1] > max(SCORE_HISTORY[1][:-1]):\n",
    "                torch.save(model.state_dict(), SAVE_WEIGHT)\n",
    "\n",
    "        if BREAK_CNT_SCORE > LIMIT_VALUE:\n",
    "            print(f\"성능 및 손실 개선이 없어서 {epoch} EPOCH에 학습 중단\")\n",
    "            break\n",
    "\n",
    "    return BCE_LOSS_HISTORY, SCORE_HISTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e864b286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 / 1000]\n",
      " - TRAIN BCE LOSS : 0.27001552501072484\n",
      "- TRAIN F1 SCORE : 0.9020243858297666\n",
      "\n",
      " - TEST BCE LOSS : 0.35142141580581665\n",
      "- TEST F1 SCORE : 0.8404558300971985\n",
      "[2 / 1000]\n",
      " - TRAIN BCE LOSS : 0.2618290808362265\n",
      "- TRAIN F1 SCORE : 0.9032264724373817\n",
      "\n",
      " - TEST BCE LOSS : 0.23300687968730927\n",
      "- TEST F1 SCORE : 0.928909957408905\n",
      "[3 / 1000]\n",
      " - TRAIN BCE LOSS : 0.2520702335362633\n",
      "- TRAIN F1 SCORE : 0.9118649053076903\n",
      "\n",
      " - TEST BCE LOSS : 0.18664777278900146\n",
      "- TEST F1 SCORE : 0.9399744868278503\n",
      "[4 / 1000]\n",
      " - TRAIN BCE LOSS : 0.22905220851923028\n",
      "- TRAIN F1 SCORE : 0.9212094731628895\n",
      "\n",
      " - TEST BCE LOSS : 0.19223730266094208\n",
      "- TEST F1 SCORE : 0.9305912852287292\n",
      "[5 / 1000]\n",
      " - TRAIN BCE LOSS : 0.21806890160466233\n",
      "- TRAIN F1 SCORE : 0.926001970966657\n",
      "\n",
      " - TEST BCE LOSS : 0.17308580875396729\n",
      "- TEST F1 SCORE : 0.9462102651596069\n",
      "[6 / 1000]\n",
      " - TRAIN BCE LOSS : 0.2110835105801622\n",
      "- TRAIN F1 SCORE : 0.9237878335018953\n",
      "\n",
      " - TEST BCE LOSS : 0.231827974319458\n",
      "- TEST F1 SCORE : 0.9086021780967712\n",
      "[7 / 1000]\n",
      " - TRAIN BCE LOSS : 0.23516555642709136\n",
      "- TRAIN F1 SCORE : 0.9120860981444517\n",
      "\n",
      " - TEST BCE LOSS : 0.1888192892074585\n",
      "- TEST F1 SCORE : 0.9252948760986328\n",
      "[8 / 1000]\n",
      " - TRAIN BCE LOSS : 0.21853277614961067\n",
      "- TRAIN F1 SCORE : 0.9222914762794971\n",
      "\n",
      " - TEST BCE LOSS : 0.1966707557439804\n",
      "- TEST F1 SCORE : 0.9212598204612732\n",
      "[9 / 1000]\n",
      " - TRAIN BCE LOSS : 0.19791500053058067\n",
      "- TRAIN F1 SCORE : 0.9327347800135612\n",
      "\n",
      " - TEST BCE LOSS : 0.18533837795257568\n",
      "- TEST F1 SCORE : 0.9249011874198914\n",
      "[10 / 1000]\n",
      " - TRAIN BCE LOSS : 0.23253553997104368\n",
      "- TRAIN F1 SCORE : 0.9167189250389735\n",
      "\n",
      " - TEST BCE LOSS : 0.14809973537921906\n",
      "- TEST F1 SCORE : 0.9502487778663635\n",
      "[11 / 1000]\n",
      " - TRAIN BCE LOSS : 0.1934946270970007\n",
      "- TRAIN F1 SCORE : 0.931138701736927\n",
      "\n",
      " - TEST BCE LOSS : 0.1662251502275467\n",
      "- TEST F1 SCORE : 0.9338521361351013\n",
      "[12 / 1000]\n",
      " - TRAIN BCE LOSS : 0.1925492275816699\n",
      "- TRAIN F1 SCORE : 0.9334759786725044\n",
      "\n",
      " - TEST BCE LOSS : 0.16666534543037415\n",
      "- TEST F1 SCORE : 0.9307189583778381\n",
      "[13 / 1000]\n",
      " - TRAIN BCE LOSS : 0.18505129249145588\n",
      "- TRAIN F1 SCORE : 0.9370607770979404\n",
      "\n",
      " - TEST BCE LOSS : 0.1633283793926239\n",
      "- TEST F1 SCORE : 0.950661838054657\n",
      "[14 / 1000]\n",
      " - TRAIN BCE LOSS : 0.19239387948376438\n",
      "- TRAIN F1 SCORE : 0.9286570611099402\n",
      "\n",
      " - TEST BCE LOSS : 0.13282684981822968\n",
      "- TEST F1 SCORE : 0.9489414691925049\n",
      "[15 / 1000]\n",
      " - TRAIN BCE LOSS : 0.18338623247109354\n",
      "- TRAIN F1 SCORE : 0.9382380048433939\n",
      "\n",
      " - TEST BCE LOSS : 0.13595527410507202\n",
      "- TEST F1 SCORE : 0.9516907930374146\n",
      "[16 / 1000]\n",
      " - TRAIN BCE LOSS : 0.1725823130303373\n",
      "- TRAIN F1 SCORE : 0.9395720176398754\n",
      "\n",
      " - TEST BCE LOSS : 0.1375514566898346\n",
      "- TEST F1 SCORE : 0.9522643685340881\n",
      "[17 / 1000]\n",
      " - TRAIN BCE LOSS : 0.16806835867464542\n",
      "- TRAIN F1 SCORE : 0.940396157403787\n",
      "\n",
      " - TEST BCE LOSS : 0.11993227154016495\n",
      "- TEST F1 SCORE : 0.9582309722900391\n",
      "[18 / 1000]\n",
      " - TRAIN BCE LOSS : 0.1801113858819008\n",
      "- TRAIN F1 SCORE : 0.9371773799260458\n",
      "\n",
      " - TEST BCE LOSS : 0.13077987730503082\n",
      "- TEST F1 SCORE : 0.9586374759674072\n",
      "[19 / 1000]\n",
      " - TRAIN BCE LOSS : 0.21964476793073118\n",
      "- TRAIN F1 SCORE : 0.9161615781486034\n",
      "\n",
      " - TEST BCE LOSS : 0.15380990505218506\n",
      "- TEST F1 SCORE : 0.9491525292396545\n",
      "[20 / 1000]\n",
      " - TRAIN BCE LOSS : 0.17575965790698925\n",
      "- TRAIN F1 SCORE : 0.9354701663057009\n",
      "\n",
      " - TEST BCE LOSS : 0.12305198609828949\n",
      "- TEST F1 SCORE : 0.9513108730316162\n",
      "[21 / 1000]\n",
      " - TRAIN BCE LOSS : 0.17938552144914865\n",
      "- TRAIN F1 SCORE : 0.935187449057897\n",
      "\n",
      " - TEST BCE LOSS : 0.12535329163074493\n",
      "- TEST F1 SCORE : 0.9479034543037415\n",
      "[22 / 1000]\n",
      " - TRAIN BCE LOSS : 0.1577274102407197\n",
      "- TRAIN F1 SCORE : 0.9396714083850384\n",
      "\n",
      " - TEST BCE LOSS : 0.15448640286922455\n",
      "- TEST F1 SCORE : 0.9322916865348816\n",
      "[23 / 1000]\n",
      " - TRAIN BCE LOSS : 0.1773553385088841\n",
      "- TRAIN F1 SCORE : 0.9380087604125341\n",
      "\n",
      " - TEST BCE LOSS : 0.12422150373458862\n",
      "- TEST F1 SCORE : 0.9596083164215088\n",
      "[24 / 1000]\n",
      " - TRAIN BCE LOSS : 0.16349920506278673\n",
      "- TRAIN F1 SCORE : 0.9413861781358719\n",
      "\n",
      " - TEST BCE LOSS : 0.11502771824598312\n",
      "- TEST F1 SCORE : 0.9590061902999878\n",
      "[25 / 1000]\n",
      " - TRAIN BCE LOSS : 0.16080316497633854\n",
      "- TRAIN F1 SCORE : 0.9440711898108324\n",
      "\n",
      " - TEST BCE LOSS : 0.24730855226516724\n",
      "- TEST F1 SCORE : 0.9086757898330688\n",
      "[26 / 1000]\n",
      " - TRAIN BCE LOSS : 0.1593278570411106\n",
      "- TRAIN F1 SCORE : 0.9437535765270392\n",
      "\n",
      " - TEST BCE LOSS : 0.11068141460418701\n",
      "- TEST F1 SCORE : 0.9543147087097168\n",
      "[27 / 1000]\n",
      " - TRAIN BCE LOSS : 0.17525327081481615\n",
      "- TRAIN F1 SCORE : 0.9347896141310533\n",
      "\n",
      " - TEST BCE LOSS : 0.10475420951843262\n",
      "- TEST F1 SCORE : 0.9606879353523254\n",
      "[28 / 1000]\n",
      " - TRAIN BCE LOSS : 0.16617017604100207\n",
      "- TRAIN F1 SCORE : 0.9407241692145666\n",
      "\n",
      " - TEST BCE LOSS : 0.11257833987474442\n",
      "- TEST F1 SCORE : 0.9620562791824341\n",
      "[29 / 1000]\n",
      " - TRAIN BCE LOSS : 0.14900913058469692\n",
      "- TRAIN F1 SCORE : 0.9477528010805448\n",
      "\n",
      " - TEST BCE LOSS : 0.10764739662408829\n",
      "- TEST F1 SCORE : 0.9669522643089294\n",
      "[30 / 1000]\n",
      " - TRAIN BCE LOSS : 0.1890484381777545\n",
      "- TRAIN F1 SCORE : 0.927580401301384\n",
      "\n",
      " - TEST BCE LOSS : 0.10184762626886368\n",
      "- TEST F1 SCORE : 0.9546599388122559\n",
      "[31 / 1000]\n",
      " - TRAIN BCE LOSS : 0.15370237299551567\n",
      "- TRAIN F1 SCORE : 0.9486852747698625\n",
      "\n",
      " - TEST BCE LOSS : 0.1144617423415184\n",
      "- TEST F1 SCORE : 0.9622411727905273\n",
      "[32 / 1000]\n",
      " - TRAIN BCE LOSS : 0.14306013480139276\n",
      "- TRAIN F1 SCORE : 0.9516730780402819\n",
      "\n",
      " - TEST BCE LOSS : 0.09807256609201431\n",
      "- TEST F1 SCORE : 0.9704433679580688\n",
      "[33 / 1000]\n",
      " - TRAIN BCE LOSS : 0.14532086167794964\n",
      "- TRAIN F1 SCORE : 0.9510857835412025\n",
      "\n",
      " - TEST BCE LOSS : 0.14558890461921692\n",
      "- TEST F1 SCORE : 0.9544364213943481\n",
      "[34 / 1000]\n",
      " - TRAIN BCE LOSS : 0.18503556633368134\n",
      "- TRAIN F1 SCORE : 0.92980732396245\n",
      "\n",
      " - TEST BCE LOSS : 0.19415105879306793\n",
      "- TEST F1 SCORE : 0.9142091274261475\n",
      "[35 / 1000]\n",
      " - TRAIN BCE LOSS : 0.17735176580026746\n",
      "- TRAIN F1 SCORE : 0.9346157150963942\n",
      "\n",
      " - TEST BCE LOSS : 0.11514563858509064\n",
      "- TEST F1 SCORE : 0.9622411727905273\n",
      "[36 / 1000]\n",
      " - TRAIN BCE LOSS : 0.1486350764365246\n",
      "- TRAIN F1 SCORE : 0.9509376970430216\n",
      "\n",
      " - TEST BCE LOSS : 0.10816623270511627\n",
      "- TEST F1 SCORE : 0.9473684430122375\n",
      "[37 / 1000]\n",
      " - TRAIN BCE LOSS : 0.15139680402353406\n",
      "- TRAIN F1 SCORE : 0.9471620296438535\n",
      "\n",
      " - TEST BCE LOSS : 0.12539829313755035\n",
      "- TEST F1 SCORE : 0.9564164876937866\n",
      "[38 / 1000]\n",
      " - TRAIN BCE LOSS : 0.1782790902070701\n",
      "- TRAIN F1 SCORE : 0.9337989663084348\n",
      "\n",
      " - TEST BCE LOSS : 0.11753863841295242\n",
      "- TEST F1 SCORE : 0.955990195274353\n",
      "[39 / 1000]\n",
      " - TRAIN BCE LOSS : 0.14350855366016427\n",
      "- TRAIN F1 SCORE : 0.9475543585916361\n",
      "\n",
      " - TEST BCE LOSS : 0.10085821151733398\n",
      "- TEST F1 SCORE : 0.9634146094322205\n",
      "[40 / 1000]\n",
      " - TRAIN BCE LOSS : 0.14908653746048608\n",
      "- TRAIN F1 SCORE : 0.9453429306546847\n",
      "\n",
      " - TEST BCE LOSS : 0.10047221183776855\n",
      "- TEST F1 SCORE : 0.9657701849937439\n",
      "[41 / 1000]\n",
      " - TRAIN BCE LOSS : 0.15295912759999433\n",
      "- TRAIN F1 SCORE : 0.9493349492549896\n",
      "\n",
      " - TEST BCE LOSS : 0.12322410196065903\n",
      "- TEST F1 SCORE : 0.941329836845398\n",
      "[42 / 1000]\n",
      " - TRAIN BCE LOSS : 0.13967558299191296\n",
      "- TRAIN F1 SCORE : 0.9504271894693375\n",
      "\n",
      " - TEST BCE LOSS : 0.09164486080408096\n",
      "- TEST F1 SCORE : 0.9655172228813171\n",
      "[43 / 1000]\n",
      " - TRAIN BCE LOSS : 0.1295856375557681\n",
      "- TRAIN F1 SCORE : 0.9571350266536077\n",
      "\n",
      " - TEST BCE LOSS : 0.09835045784711838\n",
      "- TEST F1 SCORE : 0.9562981724739075\n",
      "[44 / 1000]\n",
      " - TRAIN BCE LOSS : 0.11554946292502184\n",
      "- TRAIN F1 SCORE : 0.9591768123209476\n",
      "\n",
      " - TEST BCE LOSS : 0.08365193754434586\n",
      "- TEST F1 SCORE : 0.9691738486289978\n",
      "[45 / 1000]\n",
      " - TRAIN BCE LOSS : 0.10972625052090734\n",
      "- TRAIN F1 SCORE : 0.96152867252628\n",
      "\n",
      " - TEST BCE LOSS : 0.07978159934282303\n",
      "- TEST F1 SCORE : 0.9687108993530273\n",
      "[46 / 1000]\n",
      " - TRAIN BCE LOSS : 0.10838743955052148\n",
      "- TRAIN F1 SCORE : 0.9618891552090645\n",
      "\n",
      " - TEST BCE LOSS : 0.08217447996139526\n",
      "- TEST F1 SCORE : 0.9716399312019348\n",
      "[47 / 1000]\n",
      " - TRAIN BCE LOSS : 0.106082816918691\n",
      "- TRAIN F1 SCORE : 0.9631430432200432\n",
      "\n",
      " - TEST BCE LOSS : 0.08424708247184753\n",
      "- TEST F1 SCORE : 0.963151216506958\n",
      "[48 / 1000]\n",
      " - TRAIN BCE LOSS : 0.10921932481384526\n",
      "- TRAIN F1 SCORE : 0.9642701248327891\n",
      "\n",
      " - TEST BCE LOSS : 0.07895045727491379\n",
      "- TEST F1 SCORE : 0.9727723002433777\n",
      "[49 / 1000]\n",
      " - TRAIN BCE LOSS : 0.1081924462147678\n",
      "- TRAIN F1 SCORE : 0.9632524388531843\n",
      "\n",
      " - TEST BCE LOSS : 0.08216209709644318\n",
      "- TEST F1 SCORE : 0.9704433679580688\n",
      "[50 / 1000]\n",
      " - TRAIN BCE LOSS : 0.1086781055200845\n",
      "- TRAIN F1 SCORE : 0.9654429319004217\n",
      "\n",
      " - TEST BCE LOSS : 0.08281156420707703\n",
      "- TEST F1 SCORE : 0.9692496657371521\n",
      "[51 / 1000]\n",
      " - TRAIN BCE LOSS : 0.11023193729730944\n",
      "- TRAIN F1 SCORE : 0.9595105089247227\n",
      "\n",
      " - TEST BCE LOSS : 0.08283250033855438\n",
      "- TEST F1 SCORE : 0.9680589437484741\n",
      "[52 / 1000]\n",
      " - TRAIN BCE LOSS : 0.1147353311534971\n",
      "- TRAIN F1 SCORE : 0.9612261367340883\n",
      "\n",
      " - TEST BCE LOSS : 0.07892787456512451\n",
      "- TEST F1 SCORE : 0.968866765499115\n",
      "[53 / 1000]\n",
      " - TRAIN BCE LOSS : 0.10579575256754954\n",
      "- TRAIN F1 SCORE : 0.9633970533808073\n",
      "\n",
      " - TEST BCE LOSS : 0.07590258866548538\n",
      "- TEST F1 SCORE : 0.9687108993530273\n",
      "[54 / 1000]\n",
      " - TRAIN BCE LOSS : 0.10779815508673589\n",
      "- TRAIN F1 SCORE : 0.961169338474671\n",
      "\n",
      " - TEST BCE LOSS : 0.07950662821531296\n",
      "- TEST F1 SCORE : 0.963244616985321\n",
      "[55 / 1000]\n",
      " - TRAIN BCE LOSS : 0.11361359657409291\n",
      "- TRAIN F1 SCORE : 0.9633673752347628\n",
      "\n",
      " - TEST BCE LOSS : 0.0785004273056984\n",
      "- TEST F1 SCORE : 0.9714993834495544\n",
      "[56 / 1000]\n",
      " - TRAIN BCE LOSS : 0.10900435557899375\n",
      "- TRAIN F1 SCORE : 0.9619487524032593\n",
      "\n",
      " - TEST BCE LOSS : 0.07795579731464386\n",
      "- TEST F1 SCORE : 0.9714993834495544\n",
      "[57 / 1000]\n",
      " - TRAIN BCE LOSS : 0.1083586389819781\n",
      "- TRAIN F1 SCORE : 0.9662803734342257\n",
      "\n",
      " - TEST BCE LOSS : 0.0780632346868515\n",
      "- TEST F1 SCORE : 0.9700000286102295\n",
      "[58 / 1000]\n",
      " - TRAIN BCE LOSS : 0.10552758680811773\n",
      "- TRAIN F1 SCORE : 0.9640695191919804\n",
      "\n",
      " - TEST BCE LOSS : 0.08832429349422455\n",
      "- TEST F1 SCORE : 0.9656862616539001\n",
      "[59 / 1000]\n",
      " - TRAIN BCE LOSS : 0.10130823085394998\n",
      "- TRAIN F1 SCORE : 0.9646058479944865\n",
      "\n",
      " - TEST BCE LOSS : 0.07511981576681137\n",
      "- TEST F1 SCORE : 0.9750000238418579\n",
      "[60 / 1000]\n",
      " - TRAIN BCE LOSS : 0.1024929981213063\n",
      "- TRAIN F1 SCORE : 0.9654363455871741\n",
      "\n",
      " - TEST BCE LOSS : 0.07632438838481903\n",
      "- TEST F1 SCORE : 0.9671717286109924\n",
      "[61 / 1000]\n",
      " - TRAIN BCE LOSS : 0.10461027058772743\n",
      "- TRAIN F1 SCORE : 0.9634373759229978\n",
      "\n",
      " - TEST BCE LOSS : 0.07603666186332703\n",
      "- TEST F1 SCORE : 0.9702970385551453\n",
      "[62 / 1000]\n",
      " - TRAIN BCE LOSS : 0.10549370075265567\n",
      "- TRAIN F1 SCORE : 0.9637089644869169\n",
      "\n",
      " - TEST BCE LOSS : 0.075534388422966\n",
      "- TEST F1 SCORE : 0.9702970385551453\n",
      "[63 / 1000]\n",
      " - TRAIN BCE LOSS : 0.10241765202954412\n",
      "- TRAIN F1 SCORE : 0.9639073697229227\n",
      "\n",
      " - TEST BCE LOSS : 0.0738135427236557\n",
      "- TEST F1 SCORE : 0.9737827777862549\n",
      "[64 / 1000]\n",
      " - TRAIN BCE LOSS : 0.10284623534729083\n",
      "- TRAIN F1 SCORE : 0.966094333678484\n",
      "\n",
      " - TEST BCE LOSS : 0.07791762799024582\n",
      "- TEST F1 SCORE : 0.9656925201416016\n",
      "[65 / 1000]\n",
      " - TRAIN BCE LOSS : 0.10284452668080728\n",
      "- TRAIN F1 SCORE : 0.9646844764550527\n",
      "\n",
      " - TEST BCE LOSS : 0.0761236920952797\n",
      "- TEST F1 SCORE : 0.9711417555809021\n",
      "[66 / 1000]\n",
      " - TRAIN BCE LOSS : 0.10155185443970065\n",
      "- TRAIN F1 SCORE : 0.9666150584816933\n",
      "\n",
      " - TEST BCE LOSS : 0.07783027738332748\n",
      "- TEST F1 SCORE : 0.9727723002433777\n",
      "[67 / 1000]\n",
      " - TRAIN BCE LOSS : 0.10338818794116378\n",
      "- TRAIN F1 SCORE : 0.9648494968811671\n",
      "\n",
      " - TEST BCE LOSS : 0.0835774838924408\n",
      "- TEST F1 SCORE : 0.968137264251709\n",
      "[68 / 1000]\n",
      " - TRAIN BCE LOSS : 0.1041005258448422\n",
      "- TRAIN F1 SCORE : 0.9651952559749285\n",
      "\n",
      " - TEST BCE LOSS : 0.07545038312673569\n",
      "- TEST F1 SCORE : 0.9690210819244385\n",
      "[69 / 1000]\n",
      " - TRAIN BCE LOSS : 0.10172458935994655\n",
      "- TRAIN F1 SCORE : 0.9620702589551607\n",
      "\n",
      " - TEST BCE LOSS : 0.07890011370182037\n",
      "- TEST F1 SCORE : 0.9670885801315308\n",
      "[70 / 1000]\n",
      " - TRAIN BCE LOSS : 0.1091846317673723\n",
      "- TRAIN F1 SCORE : 0.962888682881991\n",
      "\n",
      " - TEST BCE LOSS : 0.07197684049606323\n",
      "- TEST F1 SCORE : 0.9762202501296997\n",
      "[71 / 1000]\n",
      " - TRAIN BCE LOSS : 0.10219110078954448\n",
      "- TRAIN F1 SCORE : 0.9645820036530495\n",
      "\n",
      " - TEST BCE LOSS : 0.08948369324207306\n",
      "- TEST F1 SCORE : 0.9670329689979553\n",
      "[72 / 1000]\n",
      " - TRAIN BCE LOSS : 0.10321176971774548\n",
      "- TRAIN F1 SCORE : 0.9605854662756125\n",
      "\n",
      " - TEST BCE LOSS : 0.0731942430138588\n",
      "- TEST F1 SCORE : 0.9701492786407471\n",
      "[73 / 1000]\n",
      " - TRAIN BCE LOSS : 0.10173678533950199\n",
      "- TRAIN F1 SCORE : 0.9659655963381132\n",
      "\n",
      " - TEST BCE LOSS : 0.07933113723993301\n",
      "- TEST F1 SCORE : 0.9691738486289978\n",
      "[74 / 1000]\n",
      " - TRAIN BCE LOSS : 0.10209708443532388\n",
      "- TRAIN F1 SCORE : 0.9653213967879614\n",
      "\n",
      " - TEST BCE LOSS : 0.08247743546962738\n",
      "- TEST F1 SCORE : 0.9667896628379822\n",
      "[75 / 1000]\n",
      " - TRAIN BCE LOSS : 0.0982102369889617\n",
      "- TRAIN F1 SCORE : 0.9679269368449847\n",
      "\n",
      " - TEST BCE LOSS : 0.08263611048460007\n",
      "- TEST F1 SCORE : 0.9691738486289978\n",
      "[76 / 1000]\n",
      " - TRAIN BCE LOSS : 0.10034120300163825\n",
      "- TRAIN F1 SCORE : 0.9643832817673683\n",
      "\n",
      " - TEST BCE LOSS : 0.09453616291284561\n",
      "- TEST F1 SCORE : 0.9670329689979553\n",
      "[77 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09853816013007115\n",
      "- TRAIN F1 SCORE : 0.9656826158364614\n",
      "\n",
      " - TEST BCE LOSS : 0.07570263743400574\n",
      "- TEST F1 SCORE : 0.9698492288589478\n",
      "[78 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09642181762804587\n",
      "- TRAIN F1 SCORE : 0.9665342643857002\n",
      "\n",
      " - TEST BCE LOSS : 0.07534386962652206\n",
      "- TEST F1 SCORE : 0.9724310636520386\n",
      "[79 / 1000]\n",
      " - TRAIN BCE LOSS : 0.10212145225765805\n",
      "- TRAIN F1 SCORE : 0.9657887617746989\n",
      "\n",
      " - TEST BCE LOSS : 0.07222520560026169\n",
      "- TEST F1 SCORE : 0.9750000238418579\n",
      "[80 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09766887283573548\n",
      "- TRAIN F1 SCORE : 0.9657860373457273\n",
      "\n",
      " - TEST BCE LOSS : 0.08949463814496994\n",
      "- TEST F1 SCORE : 0.9741697311401367\n",
      "[81 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09945416712434962\n",
      "- TRAIN F1 SCORE : 0.9642798254887263\n",
      "\n",
      " - TEST BCE LOSS : 0.0768325924873352\n",
      "- TEST F1 SCORE : 0.970370352268219\n",
      "[82 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09227149491198361\n",
      "- TRAIN F1 SCORE : 0.9663764300445715\n",
      "\n",
      " - TEST BCE LOSS : 0.0777474194765091\n",
      "- TEST F1 SCORE : 0.9690976738929749\n",
      "[83 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09597905810611944\n",
      "- TRAIN F1 SCORE : 0.966758289684852\n",
      "\n",
      " - TEST BCE LOSS : 0.07571029663085938\n",
      "- TEST F1 SCORE : 0.9727047085762024\n",
      "[84 / 1000]\n",
      " - TRAIN BCE LOSS : 0.08875136972831872\n",
      "- TRAIN F1 SCORE : 0.9704499530295531\n",
      "\n",
      " - TEST BCE LOSS : 0.07304517924785614\n",
      "- TEST F1 SCORE : 0.9737827777862549\n",
      "[85 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09725448365012805\n",
      "- TRAIN F1 SCORE : 0.9674928101400534\n",
      "\n",
      " - TEST BCE LOSS : 0.07955591380596161\n",
      "- TEST F1 SCORE : 0.9691738486289978\n",
      "[86 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09951531250650685\n",
      "- TRAIN F1 SCORE : 0.9659501711527506\n",
      "\n",
      " - TEST BCE LOSS : 0.07536708563566208\n",
      "- TEST F1 SCORE : 0.9726368188858032\n",
      "[87 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09635766649929185\n",
      "- TRAIN F1 SCORE : 0.9659208257993063\n",
      "\n",
      " - TEST BCE LOSS : 0.07367958873510361\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[88 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09295779520956178\n",
      "- TRAIN F1 SCORE : 0.9675069948037466\n",
      "\n",
      " - TEST BCE LOSS : 0.07528840750455856\n",
      "- TEST F1 SCORE : 0.9714285731315613\n",
      "[89 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09264151072905709\n",
      "- TRAIN F1 SCORE : 0.966493853678306\n",
      "\n",
      " - TEST BCE LOSS : 0.07595767080783844\n",
      "- TEST F1 SCORE : 0.9714285731315613\n",
      "[90 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09222054299122344\n",
      "- TRAIN F1 SCORE : 0.9693328427771727\n",
      "\n",
      " - TEST BCE LOSS : 0.07376055419445038\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[91 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09279257584906493\n",
      "- TRAIN F1 SCORE : 0.9684703449408213\n",
      "\n",
      " - TEST BCE LOSS : 0.07307291030883789\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[92 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09490675595588982\n",
      "- TRAIN F1 SCORE : 0.9667761834959189\n",
      "\n",
      " - TEST BCE LOSS : 0.07317105680704117\n",
      "- TEST F1 SCORE : 0.975062370300293\n",
      "[93 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09202044170039396\n",
      "- TRAIN F1 SCORE : 0.9689727326234182\n",
      "\n",
      " - TEST BCE LOSS : 0.07340677827596664\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[94 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09225896121157955\n",
      "- TRAIN F1 SCORE : 0.9704457831879457\n",
      "\n",
      " - TEST BCE LOSS : 0.07357174158096313\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[95 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09226501872763038\n",
      "- TRAIN F1 SCORE : 0.9693472981452942\n",
      "\n",
      " - TEST BCE LOSS : 0.07398805767297745\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[96 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09193018746251862\n",
      "- TRAIN F1 SCORE : 0.9675136171281338\n",
      "\n",
      " - TEST BCE LOSS : 0.07431118190288544\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[97 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09352350203941266\n",
      "- TRAIN F1 SCORE : 0.9677412211894989\n",
      "\n",
      " - TEST BCE LOSS : 0.07438813149929047\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[98 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09473381001347055\n",
      "- TRAIN F1 SCORE : 0.964767844726642\n",
      "\n",
      " - TEST BCE LOSS : 0.07423033565282822\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[99 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09356923905822138\n",
      "- TRAIN F1 SCORE : 0.9674595308800539\n",
      "\n",
      " - TEST BCE LOSS : 0.07466644793748856\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[100 / 1000]\n",
      " - TRAIN BCE LOSS : 0.0907880620410045\n",
      "- TRAIN F1 SCORE : 0.9693431047101816\n",
      "\n",
      " - TEST BCE LOSS : 0.07494721561670303\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[101 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09109786731035759\n",
      "- TRAIN F1 SCORE : 0.969634926567475\n",
      "\n",
      " - TEST BCE LOSS : 0.07490507513284683\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[102 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09470682773583879\n",
      "- TRAIN F1 SCORE : 0.9684460846086343\n",
      "\n",
      " - TEST BCE LOSS : 0.07487314939498901\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[103 / 1000]\n",
      " - TRAIN BCE LOSS : 0.08921875847348322\n",
      "- TRAIN F1 SCORE : 0.9719242428739866\n",
      "\n",
      " - TEST BCE LOSS : 0.07468339800834656\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[104 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09268096799496561\n",
      "- TRAIN F1 SCORE : 0.969254749516646\n",
      "\n",
      " - TEST BCE LOSS : 0.07469364255666733\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[105 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09376376746998479\n",
      "- TRAIN F1 SCORE : 0.9668440967798233\n",
      "\n",
      " - TEST BCE LOSS : 0.07469145208597183\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[106 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09132581138207267\n",
      "- TRAIN F1 SCORE : 0.9678970351815224\n",
      "\n",
      " - TEST BCE LOSS : 0.07466690987348557\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[107 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09088800567163464\n",
      "- TRAIN F1 SCORE : 0.967803131788969\n",
      "\n",
      " - TEST BCE LOSS : 0.07472947984933853\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[108 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09322336358794321\n",
      "- TRAIN F1 SCORE : 0.9694458531836668\n",
      "\n",
      " - TEST BCE LOSS : 0.0747474879026413\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[109 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09930465828316908\n",
      "- TRAIN F1 SCORE : 0.9668448741237322\n",
      "\n",
      " - TEST BCE LOSS : 0.07476027309894562\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[110 / 1000]\n",
      " - TRAIN BCE LOSS : 0.0950185958839332\n",
      "- TRAIN F1 SCORE : 0.9652602026859919\n",
      "\n",
      " - TEST BCE LOSS : 0.0747331976890564\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[111 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09957466639267902\n",
      "- TRAIN F1 SCORE : 0.9660639899472395\n",
      "\n",
      " - TEST BCE LOSS : 0.07473048567771912\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[112 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09041824849555269\n",
      "- TRAIN F1 SCORE : 0.9692548587918282\n",
      "\n",
      " - TEST BCE LOSS : 0.07474638521671295\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[113 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09142887953203171\n",
      "- TRAIN F1 SCORE : 0.9703098945319653\n",
      "\n",
      " - TEST BCE LOSS : 0.07477455586194992\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[114 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09093770978506655\n",
      "- TRAIN F1 SCORE : 0.9667392186820507\n",
      "\n",
      " - TEST BCE LOSS : 0.07476212084293365\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[115 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09513232344761491\n",
      "- TRAIN F1 SCORE : 0.9648738565544287\n",
      "\n",
      " - TEST BCE LOSS : 0.07476206123828888\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[116 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09245992931149279\n",
      "- TRAIN F1 SCORE : 0.967727200438579\n",
      "\n",
      " - TEST BCE LOSS : 0.07476150989532471\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[117 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09320372211125989\n",
      "- TRAIN F1 SCORE : 0.9662045513590177\n",
      "\n",
      " - TEST BCE LOSS : 0.07476019859313965\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[118 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09356355022949477\n",
      "- TRAIN F1 SCORE : 0.9666041086117426\n",
      "\n",
      " - TEST BCE LOSS : 0.07476062327623367\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[119 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09299724692633997\n",
      "- TRAIN F1 SCORE : 0.9682328502337137\n",
      "\n",
      " - TEST BCE LOSS : 0.07476091384887695\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[120 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09543605505799253\n",
      "- TRAIN F1 SCORE : 0.9672587191065153\n",
      "\n",
      " - TEST BCE LOSS : 0.0747610330581665\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[121 / 1000]\n",
      " - TRAIN BCE LOSS : 0.090808096244776\n",
      "- TRAIN F1 SCORE : 0.9689852818846703\n",
      "\n",
      " - TEST BCE LOSS : 0.07476076483726501\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[122 / 1000]\n",
      " - TRAIN BCE LOSS : 0.0933049672942919\n",
      "- TRAIN F1 SCORE : 0.9672508041063944\n",
      "\n",
      " - TEST BCE LOSS : 0.0747603327035904\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[123 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09131125298639138\n",
      "- TRAIN F1 SCORE : 0.969296183437109\n",
      "\n",
      " - TEST BCE LOSS : 0.07476013898849487\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[124 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09465332542701314\n",
      "- TRAIN F1 SCORE : 0.9673084591825803\n",
      "\n",
      " - TEST BCE LOSS : 0.07476051151752472\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[125 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09292031374449532\n",
      "- TRAIN F1 SCORE : 0.9676139528552691\n",
      "\n",
      " - TEST BCE LOSS : 0.0747605636715889\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[126 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09482393173190455\n",
      "- TRAIN F1 SCORE : 0.9692633301019669\n",
      "\n",
      " - TEST BCE LOSS : 0.07475980371236801\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[127 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09385950956493616\n",
      "- TRAIN F1 SCORE : 0.9666121006011963\n",
      "\n",
      " - TEST BCE LOSS : 0.07475998252630234\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[128 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09264260545993845\n",
      "- TRAIN F1 SCORE : 0.9684706715246042\n",
      "\n",
      " - TEST BCE LOSS : 0.07475953549146652\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[129 / 1000]\n",
      " - TRAIN BCE LOSS : 0.0936985788284801\n",
      "- TRAIN F1 SCORE : 0.9684930890798569\n",
      "\n",
      " - TEST BCE LOSS : 0.07475916296243668\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[130 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09957452894498904\n",
      "- TRAIN F1 SCORE : 0.967052680750688\n",
      "\n",
      " - TEST BCE LOSS : 0.07475122064352036\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[131 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09435210706821333\n",
      "- TRAIN F1 SCORE : 0.9665789194405079\n",
      "\n",
      " - TEST BCE LOSS : 0.07475995272397995\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[132 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09234879220214982\n",
      "- TRAIN F1 SCORE : 0.9652099696298441\n",
      "\n",
      " - TEST BCE LOSS : 0.07476065307855606\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[133 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09845046291593462\n",
      "- TRAIN F1 SCORE : 0.966124277561903\n",
      "\n",
      " - TEST BCE LOSS : 0.07476112246513367\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[134 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09383557236287743\n",
      "- TRAIN F1 SCORE : 0.9685164988040924\n",
      "\n",
      " - TEST BCE LOSS : 0.07476022839546204\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[135 / 1000]\n",
      " - TRAIN BCE LOSS : 0.08767526076796155\n",
      "- TRAIN F1 SCORE : 0.9704005060096582\n",
      "\n",
      " - TEST BCE LOSS : 0.07476026564836502\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[136 / 1000]\n",
      " - TRAIN BCE LOSS : 0.0935631804750301\n",
      "- TRAIN F1 SCORE : 0.967818004389604\n",
      "\n",
      " - TEST BCE LOSS : 0.0747605636715889\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[137 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09193724634436269\n",
      "- TRAIN F1 SCORE : 0.9674874357879162\n",
      "\n",
      " - TEST BCE LOSS : 0.07476132363080978\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[138 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09438460861565545\n",
      "- TRAIN F1 SCORE : 0.9676448330283165\n",
      "\n",
      " - TEST BCE LOSS : 0.07476199418306351\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[139 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09037769469432533\n",
      "- TRAIN F1 SCORE : 0.9708225230375925\n",
      "\n",
      " - TEST BCE LOSS : 0.07476132363080978\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[140 / 1000]\n",
      " - TRAIN BCE LOSS : 0.0936058812464277\n",
      "- TRAIN F1 SCORE : 0.9691464006900787\n",
      "\n",
      " - TEST BCE LOSS : 0.07476244866847992\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[141 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09157166536897421\n",
      "- TRAIN F1 SCORE : 0.9699192307889462\n",
      "\n",
      " - TEST BCE LOSS : 0.07476259768009186\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[142 / 1000]\n",
      " - TRAIN BCE LOSS : 0.091569440458746\n",
      "- TRAIN F1 SCORE : 0.9686341397464275\n",
      "\n",
      " - TEST BCE LOSS : 0.07476216554641724\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[143 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09340508782770485\n",
      "- TRAIN F1 SCORE : 0.9705376227696737\n",
      "\n",
      " - TEST BCE LOSS : 0.07476300001144409\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[144 / 1000]\n",
      " - TRAIN BCE LOSS : 0.0928287753292049\n",
      "- TRAIN F1 SCORE : 0.9682061709463596\n",
      "\n",
      " - TEST BCE LOSS : 0.07476286590099335\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[145 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09394580502218257\n",
      "- TRAIN F1 SCORE : 0.9694280835489432\n",
      "\n",
      " - TEST BCE LOSS : 0.07476259022951126\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[146 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09011573581180225\n",
      "- TRAIN F1 SCORE : 0.9702100828289986\n",
      "\n",
      " - TEST BCE LOSS : 0.07476236671209335\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[147 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09556991048157215\n",
      "- TRAIN F1 SCORE : 0.9681365365783373\n",
      "\n",
      " - TEST BCE LOSS : 0.07476227730512619\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[148 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09012972932153691\n",
      "- TRAIN F1 SCORE : 0.9704189822077751\n",
      "\n",
      " - TEST BCE LOSS : 0.07476232200860977\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[149 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09014546974018837\n",
      "- TRAIN F1 SCORE : 0.9685090308388075\n",
      "\n",
      " - TEST BCE LOSS : 0.07476197928190231\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[150 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09090753066508721\n",
      "- TRAIN F1 SCORE : 0.9700449133912722\n",
      "\n",
      " - TEST BCE LOSS : 0.07476174831390381\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[151 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09476136404555291\n",
      "- TRAIN F1 SCORE : 0.966720043371121\n",
      "\n",
      " - TEST BCE LOSS : 0.07476156949996948\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[152 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09176632319577038\n",
      "- TRAIN F1 SCORE : 0.9703682996332645\n",
      "\n",
      " - TEST BCE LOSS : 0.0747615396976471\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[153 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09130206824435542\n",
      "- TRAIN F1 SCORE : 0.9694454583028952\n",
      "\n",
      " - TEST BCE LOSS : 0.07476077973842621\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[154 / 1000]\n",
      " - TRAIN BCE LOSS : 0.0915100610582158\n",
      "- TRAIN F1 SCORE : 0.9696123662094275\n",
      "\n",
      " - TEST BCE LOSS : 0.07476154714822769\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[155 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09203567266619454\n",
      "- TRAIN F1 SCORE : 0.9691214039921761\n",
      "\n",
      " - TEST BCE LOSS : 0.07476141303777695\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[156 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09144218269890796\n",
      "- TRAIN F1 SCORE : 0.9703564830124378\n",
      "\n",
      " - TEST BCE LOSS : 0.07476097345352173\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[157 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09275680299227436\n",
      "- TRAIN F1 SCORE : 0.967754972477754\n",
      "\n",
      " - TEST BCE LOSS : 0.07476069778203964\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[158 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09252474235836416\n",
      "- TRAIN F1 SCORE : 0.9675075573225816\n",
      "\n",
      " - TEST BCE LOSS : 0.07476123422384262\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[159 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09405750699806958\n",
      "- TRAIN F1 SCORE : 0.9676674554745356\n",
      "\n",
      " - TEST BCE LOSS : 0.07476073503494263\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[160 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09185129035419475\n",
      "- TRAIN F1 SCORE : 0.9706308953464031\n",
      "\n",
      " - TEST BCE LOSS : 0.07476165145635605\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[161 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09045483680286755\n",
      "- TRAIN F1 SCORE : 0.9695440083742142\n",
      "\n",
      " - TEST BCE LOSS : 0.07476099580526352\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[162 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09218317580719788\n",
      "- TRAIN F1 SCORE : 0.9708565808832645\n",
      "\n",
      " - TEST BCE LOSS : 0.07476165145635605\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[163 / 1000]\n",
      " - TRAIN BCE LOSS : 0.0946302965361004\n",
      "- TRAIN F1 SCORE : 0.9680613614618778\n",
      "\n",
      " - TEST BCE LOSS : 0.074760802090168\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[164 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09066975173967269\n",
      "- TRAIN F1 SCORE : 0.968683642645677\n",
      "\n",
      " - TEST BCE LOSS : 0.07476112246513367\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[165 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09485309477895498\n",
      "- TRAIN F1 SCORE : 0.9684369924167792\n",
      "\n",
      " - TEST BCE LOSS : 0.07476155459880829\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[166 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09230874381804217\n",
      "- TRAIN F1 SCORE : 0.9684011439482371\n",
      "\n",
      " - TEST BCE LOSS : 0.07476019114255905\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[167 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09682103750916819\n",
      "- TRAIN F1 SCORE : 0.9686641717950503\n",
      "\n",
      " - TEST BCE LOSS : 0.07475975155830383\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[168 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09236789937131107\n",
      "- TRAIN F1 SCORE : 0.9670819168289503\n",
      "\n",
      " - TEST BCE LOSS : 0.07475171238183975\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[169 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09432156884577125\n",
      "- TRAIN F1 SCORE : 0.9678275945285956\n",
      "\n",
      " - TEST BCE LOSS : 0.07475970685482025\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[170 / 1000]\n",
      " - TRAIN BCE LOSS : 0.0924898818678533\n",
      "- TRAIN F1 SCORE : 0.9692148938775063\n",
      "\n",
      " - TEST BCE LOSS : 0.07475817948579788\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[171 / 1000]\n",
      " - TRAIN BCE LOSS : 0.0951592786392818\n",
      "- TRAIN F1 SCORE : 0.9679772692422072\n",
      "\n",
      " - TEST BCE LOSS : 0.07475853711366653\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[172 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09435420397979517\n",
      "- TRAIN F1 SCORE : 0.9698959141969681\n",
      "\n",
      " - TEST BCE LOSS : 0.07475989311933517\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[173 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09329410531790927\n",
      "- TRAIN F1 SCORE : 0.9665211314956347\n",
      "\n",
      " - TEST BCE LOSS : 0.07475801557302475\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[174 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09574998488339286\n",
      "- TRAIN F1 SCORE : 0.9639205945034822\n",
      "\n",
      " - TEST BCE LOSS : 0.0747501403093338\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[175 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09217979510625203\n",
      "- TRAIN F1 SCORE : 0.9681564631561438\n",
      "\n",
      " - TEST BCE LOSS : 0.07475026696920395\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[176 / 1000]\n",
      " - TRAIN BCE LOSS : 0.10137662815395743\n",
      "- TRAIN F1 SCORE : 0.9654132090508938\n",
      "\n",
      " - TEST BCE LOSS : 0.07475762069225311\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[177 / 1000]\n",
      " - TRAIN BCE LOSS : 0.10132314148359\n",
      "- TRAIN F1 SCORE : 0.9669834213952223\n",
      "\n",
      " - TEST BCE LOSS : 0.07474900782108307\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[178 / 1000]\n",
      " - TRAIN BCE LOSS : 0.0931043940751503\n",
      "- TRAIN F1 SCORE : 0.9687306260069212\n",
      "\n",
      " - TEST BCE LOSS : 0.07474891096353531\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[179 / 1000]\n",
      " - TRAIN BCE LOSS : 0.08952246214418362\n",
      "- TRAIN F1 SCORE : 0.9718041705588499\n",
      "\n",
      " - TEST BCE LOSS : 0.07475735247135162\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[180 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09332109848037362\n",
      "- TRAIN F1 SCORE : 0.9687952982882658\n",
      "\n",
      " - TEST BCE LOSS : 0.07475736737251282\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[181 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09309525263961405\n",
      "- TRAIN F1 SCORE : 0.9695707187056541\n",
      "\n",
      " - TEST BCE LOSS : 0.07475845515727997\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[182 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09216492301008354\n",
      "- TRAIN F1 SCORE : 0.9693329421182474\n",
      "\n",
      " - TEST BCE LOSS : 0.0747581347823143\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[183 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09135758709938575\n",
      "- TRAIN F1 SCORE : 0.9693662114441395\n",
      "\n",
      " - TEST BCE LOSS : 0.07475880533456802\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[184 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09038998023606837\n",
      "- TRAIN F1 SCORE : 0.9678656868636608\n",
      "\n",
      " - TEST BCE LOSS : 0.07475880533456802\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[185 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09215787324743967\n",
      "- TRAIN F1 SCORE : 0.9705620259046555\n",
      "\n",
      " - TEST BCE LOSS : 0.0747588500380516\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[186 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09706537992072602\n",
      "- TRAIN F1 SCORE : 0.9654423892498016\n",
      "\n",
      " - TEST BCE LOSS : 0.07475905865430832\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[187 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09357105381786823\n",
      "- TRAIN F1 SCORE : 0.966550674289465\n",
      "\n",
      " - TEST BCE LOSS : 0.07475895434617996\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[188 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09315559865596394\n",
      "- TRAIN F1 SCORE : 0.9686609705289205\n",
      "\n",
      " - TEST BCE LOSS : 0.07475894689559937\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[189 / 1000]\n",
      " - TRAIN BCE LOSS : 0.08964248036500067\n",
      "- TRAIN F1 SCORE : 0.9692534431815147\n",
      "\n",
      " - TEST BCE LOSS : 0.07475928962230682\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[190 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09227187861688435\n",
      "- TRAIN F1 SCORE : 0.9683805890381336\n",
      "\n",
      " - TEST BCE LOSS : 0.07475916296243668\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[191 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09559940622420982\n",
      "- TRAIN F1 SCORE : 0.9690069121619066\n",
      "\n",
      " - TEST BCE LOSS : 0.0747593343257904\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[192 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09963782880610476\n",
      "- TRAIN F1 SCORE : 0.9633084237575531\n",
      "\n",
      " - TEST BCE LOSS : 0.07475873827934265\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[193 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09122892550658435\n",
      "- TRAIN F1 SCORE : 0.9707708085576693\n",
      "\n",
      " - TEST BCE LOSS : 0.07475952059030533\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[194 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09699550678487867\n",
      "- TRAIN F1 SCORE : 0.9653666876256466\n",
      "\n",
      " - TEST BCE LOSS : 0.07475712150335312\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[195 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09468147721296798\n",
      "- TRAIN F1 SCORE : 0.9684409089386463\n",
      "\n",
      " - TEST BCE LOSS : 0.0747566670179367\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[196 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09395530784968287\n",
      "- TRAIN F1 SCORE : 0.9686081049342951\n",
      "\n",
      " - TEST BCE LOSS : 0.07475645840167999\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[197 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09549834885789703\n",
      "- TRAIN F1 SCORE : 0.9683172069489956\n",
      "\n",
      " - TEST BCE LOSS : 0.07475646585226059\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[198 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09136481420136988\n",
      "- TRAIN F1 SCORE : 0.9669621760646502\n",
      "\n",
      " - TEST BCE LOSS : 0.07475646585226059\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[199 / 1000]\n",
      " - TRAIN BCE LOSS : 0.08964635907129075\n",
      "- TRAIN F1 SCORE : 0.9703122278054556\n",
      "\n",
      " - TEST BCE LOSS : 0.07475665956735611\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[200 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09081169031560421\n",
      "- TRAIN F1 SCORE : 0.9693585063020388\n",
      "\n",
      " - TEST BCE LOSS : 0.07475826144218445\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[201 / 1000]\n",
      " - TRAIN BCE LOSS : 0.0929052047431469\n",
      "- TRAIN F1 SCORE : 0.9681425988674164\n",
      "\n",
      " - TEST BCE LOSS : 0.07475662231445312\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[202 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09439899970311671\n",
      "- TRAIN F1 SCORE : 0.9659560744961103\n",
      "\n",
      " - TEST BCE LOSS : 0.07475848495960236\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[203 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09229020754961918\n",
      "- TRAIN F1 SCORE : 0.9670414216816425\n",
      "\n",
      " - TEST BCE LOSS : 0.0747581496834755\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[204 / 1000]\n",
      " - TRAIN BCE LOSS : 0.08909955824492499\n",
      "- TRAIN F1 SCORE : 0.969921718041102\n",
      "\n",
      " - TEST BCE LOSS : 0.07475868612527847\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[205 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09046231008445223\n",
      "- TRAIN F1 SCORE : 0.9683527660866579\n",
      "\n",
      " - TEST BCE LOSS : 0.0747581496834755\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[206 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09085421186561386\n",
      "- TRAIN F1 SCORE : 0.968596895535787\n",
      "\n",
      " - TEST BCE LOSS : 0.07476609200239182\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[207 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09188423643354326\n",
      "- TRAIN F1 SCORE : 0.9666457250714302\n",
      "\n",
      " - TEST BCE LOSS : 0.07476633787155151\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[208 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09131801361218095\n",
      "- TRAIN F1 SCORE : 0.9696945933004221\n",
      "\n",
      " - TEST BCE LOSS : 0.07476602494716644\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[209 / 1000]\n",
      " - TRAIN BCE LOSS : 0.08876574408107747\n",
      "- TRAIN F1 SCORE : 0.9708952171107134\n",
      "\n",
      " - TEST BCE LOSS : 0.07475652545690536\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[210 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09151023005445798\n",
      "- TRAIN F1 SCORE : 0.968206238001585\n",
      "\n",
      " - TEST BCE LOSS : 0.0747571662068367\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[211 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09167489359000076\n",
      "- TRAIN F1 SCORE : 0.9669081966082255\n",
      "\n",
      " - TEST BCE LOSS : 0.0747666284441948\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[212 / 1000]\n",
      " - TRAIN BCE LOSS : 0.0916084403579589\n",
      "- TRAIN F1 SCORE : 0.9698677447934946\n",
      "\n",
      " - TEST BCE LOSS : 0.07475629448890686\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[213 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09005049321179588\n",
      "- TRAIN F1 SCORE : 0.9687757007777691\n",
      "\n",
      " - TEST BCE LOSS : 0.07475776970386505\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[214 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09728247594709198\n",
      "- TRAIN F1 SCORE : 0.9648849194248518\n",
      "\n",
      " - TEST BCE LOSS : 0.07476577907800674\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[215 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09454057679977268\n",
      "- TRAIN F1 SCORE : 0.9673356302082539\n",
      "\n",
      " - TEST BCE LOSS : 0.07476574182510376\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[216 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09168958850204945\n",
      "- TRAIN F1 SCORE : 0.9709935660163561\n",
      "\n",
      " - TEST BCE LOSS : 0.07476706802845001\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[217 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09205127039846654\n",
      "- TRAIN F1 SCORE : 0.9674043295284113\n",
      "\n",
      " - TEST BCE LOSS : 0.07476671785116196\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[218 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09614937977554898\n",
      "- TRAIN F1 SCORE : 0.9682684416572253\n",
      "\n",
      " - TEST BCE LOSS : 0.07476647943258286\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[219 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09511469801266988\n",
      "- TRAIN F1 SCORE : 0.970330094297727\n",
      "\n",
      " - TEST BCE LOSS : 0.07476666569709778\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[220 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09187635480581473\n",
      "- TRAIN F1 SCORE : 0.9676558971405029\n",
      "\n",
      " - TEST BCE LOSS : 0.07476631551980972\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[221 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09269954753108323\n",
      "- TRAIN F1 SCORE : 0.9686954853435358\n",
      "\n",
      " - TEST BCE LOSS : 0.07476543635129929\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[222 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09119710302911699\n",
      "- TRAIN F1 SCORE : 0.9661320845286051\n",
      "\n",
      " - TEST BCE LOSS : 0.07476630806922913\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[223 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09368520012746255\n",
      "- TRAIN F1 SCORE : 0.9678546339273453\n",
      "\n",
      " - TEST BCE LOSS : 0.0747649073600769\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[224 / 1000]\n",
      " - TRAIN BCE LOSS : 0.0935048804579613\n",
      "- TRAIN F1 SCORE : 0.9678338542580605\n",
      "\n",
      " - TEST BCE LOSS : 0.07476571947336197\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[225 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09421216176512341\n",
      "- TRAIN F1 SCORE : 0.967655664930741\n",
      "\n",
      " - TEST BCE LOSS : 0.074766606092453\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[226 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09202892325508098\n",
      "- TRAIN F1 SCORE : 0.9679062577585379\n",
      "\n",
      " - TEST BCE LOSS : 0.07476615160703659\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[227 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09123327824636362\n",
      "- TRAIN F1 SCORE : 0.9691169708967209\n",
      "\n",
      " - TEST BCE LOSS : 0.07476623356342316\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[228 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09041450285197546\n",
      "- TRAIN F1 SCORE : 0.9694899618625641\n",
      "\n",
      " - TEST BCE LOSS : 0.07475608587265015\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[229 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09017222033192714\n",
      "- TRAIN F1 SCORE : 0.9694054288168749\n",
      "\n",
      " - TEST BCE LOSS : 0.0747557058930397\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[230 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09286063897889107\n",
      "- TRAIN F1 SCORE : 0.9671709661682447\n",
      "\n",
      " - TEST BCE LOSS : 0.07475725561380386\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[231 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09309410466812551\n",
      "- TRAIN F1 SCORE : 0.9694133798281351\n",
      "\n",
      " - TEST BCE LOSS : 0.07475548982620239\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[232 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09294347901595756\n",
      "- TRAIN F1 SCORE : 0.9695481893916925\n",
      "\n",
      " - TEST BCE LOSS : 0.07475566864013672\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[233 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09416093479376286\n",
      "- TRAIN F1 SCORE : 0.9679515150686105\n",
      "\n",
      " - TEST BCE LOSS : 0.07476504892110825\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[234 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09205675742123276\n",
      "- TRAIN F1 SCORE : 0.9700315905114015\n",
      "\n",
      " - TEST BCE LOSS : 0.07476530969142914\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[235 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09330598734474431\n",
      "- TRAIN F1 SCORE : 0.9683564503987631\n",
      "\n",
      " - TEST BCE LOSS : 0.07476533949375153\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[236 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09212871572041574\n",
      "- TRAIN F1 SCORE : 0.9696278298894564\n",
      "\n",
      " - TEST BCE LOSS : 0.07476577162742615\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[237 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09142472063346456\n",
      "- TRAIN F1 SCORE : 0.9693841847280661\n",
      "\n",
      " - TEST BCE LOSS : 0.07476607710123062\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[238 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09587746039809038\n",
      "- TRAIN F1 SCORE : 0.9668580840031306\n",
      "\n",
      " - TEST BCE LOSS : 0.07476747781038284\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[239 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09016144500734906\n",
      "- TRAIN F1 SCORE : 0.9690530846516291\n",
      "\n",
      " - TEST BCE LOSS : 0.07476744055747986\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[240 / 1000]\n",
      " - TRAIN BCE LOSS : 0.08744950549832235\n",
      "- TRAIN F1 SCORE : 0.9723583857218424\n",
      "\n",
      " - TEST BCE LOSS : 0.0747666209936142\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[241 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09142241805481414\n",
      "- TRAIN F1 SCORE : 0.9680832313994566\n",
      "\n",
      " - TEST BCE LOSS : 0.07476621121168137\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[242 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09158538922201842\n",
      "- TRAIN F1 SCORE : 0.9704444656769434\n",
      "\n",
      " - TEST BCE LOSS : 0.07476704567670822\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[243 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09134121171276395\n",
      "- TRAIN F1 SCORE : 0.9692195169627666\n",
      "\n",
      " - TEST BCE LOSS : 0.07476688176393509\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[244 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09143532149028033\n",
      "- TRAIN F1 SCORE : 0.9678293031950792\n",
      "\n",
      " - TEST BCE LOSS : 0.07476761937141418\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[245 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09023000431867938\n",
      "- TRAIN F1 SCORE : 0.9687029098471006\n",
      "\n",
      " - TEST BCE LOSS : 0.07476772367954254\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[246 / 1000]\n",
      " - TRAIN BCE LOSS : 0.0925426105192552\n",
      "- TRAIN F1 SCORE : 0.9661387838423252\n",
      "\n",
      " - TEST BCE LOSS : 0.07476764917373657\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[247 / 1000]\n",
      " - TRAIN BCE LOSS : 0.0921694067073986\n",
      "- TRAIN F1 SCORE : 0.9667667411267757\n",
      "\n",
      " - TEST BCE LOSS : 0.07476823776960373\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[248 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09740927846481402\n",
      "- TRAIN F1 SCORE : 0.969335038214922\n",
      "\n",
      " - TEST BCE LOSS : 0.07476797699928284\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "[249 / 1000]\n",
      " - TRAIN BCE LOSS : 0.09376504578782867\n",
      "- TRAIN F1 SCORE : 0.967793965091308\n",
      "\n",
      " - TEST BCE LOSS : 0.07476814091205597\n",
      "- TEST F1 SCORE : 0.9738480448722839\n",
      "성능 및 손실 개선이 없어서 249 EPOCH에 학습 중단\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 시작\n",
    "bce_loss, f1_score = training(fall_detect_model, trainDL, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6815900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 100, 40])\n"
     ]
    }
   ],
   "source": [
    "for x, y in trainDL:\n",
    "    print(x.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "861e241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = r\"./Test_Dataset/test_video2.mp4\"\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "907dab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=0,\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.7,\n",
    "    smooth_landmarks=True\n",
    ")\n",
    "\n",
    "important_landmarks = [\n",
    "    0, 11, 12, 13, 14, 15, 16,\n",
    "    23, 24, 25, 26, 29, 30\n",
    "]\n",
    "\n",
    "test_video = pd.DataFrame(columns = [\"frame\", \"landmark_id\", \"x\", \"y\", \"z\"])\n",
    "\n",
    "frame_count = 0\n",
    "processed_frame = 0\n",
    "\n",
    "cap = cv2.VideoCapture(video)\n",
    "original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "skip_interval = max(1, round(original_fps / 10))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    # 예: 90도 시계 방향으로 회전 (세로 영상이 눕는 경우)\n",
    "    frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if frame_count % skip_interval == 0:\n",
    "        # frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "        processed_frame += 1\n",
    "        frame = cv2.resize(frame, (640, 480))\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            for idx in important_landmarks:\n",
    "                landmark = results.pose_landmarks.landmark[idx]\n",
    "                test_video.loc[len(test_video)] = [processed_frame, idx, landmark.x, landmark.y, landmark.z]\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b21a64bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame</th>\n",
       "      <th>landmark_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.495077</td>\n",
       "      <td>0.202133</td>\n",
       "      <td>-0.259547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.592108</td>\n",
       "      <td>0.307687</td>\n",
       "      <td>-0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.399682</td>\n",
       "      <td>0.322056</td>\n",
       "      <td>-0.001780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.647337</td>\n",
       "      <td>0.425211</td>\n",
       "      <td>0.014860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.329309</td>\n",
       "      <td>0.407353</td>\n",
       "      <td>0.015185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>116.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.371051</td>\n",
       "      <td>0.565896</td>\n",
       "      <td>-0.008246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>116.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.573948</td>\n",
       "      <td>0.641452</td>\n",
       "      <td>-0.297894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>116.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.377047</td>\n",
       "      <td>0.724311</td>\n",
       "      <td>-0.145936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>116.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.581554</td>\n",
       "      <td>0.861283</td>\n",
       "      <td>-0.186450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>116.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.394022</td>\n",
       "      <td>0.823269</td>\n",
       "      <td>0.125205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1482 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      frame  landmark_id         x         y         z\n",
       "0       3.0          0.0  0.495077  0.202133 -0.259547\n",
       "1       3.0         11.0  0.592108  0.307687 -0.000086\n",
       "2       3.0         12.0  0.399682  0.322056 -0.001780\n",
       "3       3.0         13.0  0.647337  0.425211  0.014860\n",
       "4       3.0         14.0  0.329309  0.407353  0.015185\n",
       "...     ...          ...       ...       ...       ...\n",
       "1477  116.0         24.0  0.371051  0.565896 -0.008246\n",
       "1478  116.0         25.0  0.573948  0.641452 -0.297894\n",
       "1479  116.0         26.0  0.377047  0.724311 -0.145936\n",
       "1480  116.0         29.0  0.581554  0.861283 -0.186450\n",
       "1481  116.0         30.0  0.394022  0.823269  0.125205\n",
       "\n",
       "[1482 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de404e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame</th>\n",
       "      <th>landmark_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.495077</td>\n",
       "      <td>0.202133</td>\n",
       "      <td>-0.259547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.592108</td>\n",
       "      <td>0.307687</td>\n",
       "      <td>-0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.399682</td>\n",
       "      <td>0.322056</td>\n",
       "      <td>-0.001780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.647337</td>\n",
       "      <td>0.425211</td>\n",
       "      <td>0.014860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.329309</td>\n",
       "      <td>0.407353</td>\n",
       "      <td>0.015185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>298.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.371051</td>\n",
       "      <td>0.565896</td>\n",
       "      <td>-0.008246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>298.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.573948</td>\n",
       "      <td>0.641452</td>\n",
       "      <td>-0.297894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>298.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.377047</td>\n",
       "      <td>0.724311</td>\n",
       "      <td>-0.145936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2111</th>\n",
       "      <td>298.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.581554</td>\n",
       "      <td>0.861283</td>\n",
       "      <td>-0.186450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>298.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.394022</td>\n",
       "      <td>0.823269</td>\n",
       "      <td>0.125205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2288 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      frame  landmark_id         x         y         z\n",
       "0       1.0          0.0  0.495077  0.202133 -0.259547\n",
       "176     1.0         11.0  0.592108  0.307687 -0.000086\n",
       "352     1.0         12.0  0.399682  0.322056 -0.001780\n",
       "528     1.0         13.0  0.647337  0.425211  0.014860\n",
       "704     1.0         14.0  0.329309  0.407353  0.015185\n",
       "...     ...          ...       ...       ...       ...\n",
       "1583  298.0         24.0  0.371051  0.565896 -0.008246\n",
       "1759  298.0         25.0  0.573948  0.641452 -0.297894\n",
       "1935  298.0         26.0  0.377047  0.724311 -0.145936\n",
       "2111  298.0         29.0  0.581554  0.861283 -0.186450\n",
       "2287  298.0         30.0  0.394022  0.823269  0.125205\n",
       "\n",
       "[2288 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 프레임과 랜드마크 ID 목록 생성\n",
    "all_frames = np.arange(1, 301, 3)\n",
    "all_landmarks = test_video['landmark_id'].unique()\n",
    "\n",
    "df_frames = test_video[\"frame\"].unique()\n",
    "\n",
    "frame_list = []\n",
    "landmark_list = []\n",
    "\n",
    "for frame in all_frames:\n",
    "    if frame not in df_frames:\n",
    "        for landmark in all_landmarks:\n",
    "            frame_list.append(frame)\n",
    "            landmark_list.append(landmark)\n",
    "\n",
    "add_row = pd.DataFrame({\"frame\" : frame_list, \"landmark_id\" : landmark_list})\n",
    "\n",
    "test_video = pd.concat([test_video, add_row], ignore_index = True)\n",
    "\n",
    "test_video = test_video.groupby(\"landmark_id\").apply(lambda x : x.sort_values(by = [\"frame\", \"landmark_id\"]).interpolate().ffill().bfill()).reset_index(drop=True)\n",
    "test_video = test_video.sort_values(by = [\"frame\", \"landmark_id\"])\n",
    "\n",
    "if len(test_video) > 3900:\n",
    "    test_video = test_video[:3900]\n",
    "\n",
    "test_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f44bfc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame</th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_11</th>\n",
       "      <th>x_12</th>\n",
       "      <th>x_13</th>\n",
       "      <th>x_14</th>\n",
       "      <th>x_15</th>\n",
       "      <th>x_16</th>\n",
       "      <th>x_23</th>\n",
       "      <th>x_24</th>\n",
       "      <th>...</th>\n",
       "      <th>z_13</th>\n",
       "      <th>z_14</th>\n",
       "      <th>z_15</th>\n",
       "      <th>z_16</th>\n",
       "      <th>z_23</th>\n",
       "      <th>z_24</th>\n",
       "      <th>z_25</th>\n",
       "      <th>z_26</th>\n",
       "      <th>z_29</th>\n",
       "      <th>z_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.495077</td>\n",
       "      <td>0.592108</td>\n",
       "      <td>0.399682</td>\n",
       "      <td>0.647337</td>\n",
       "      <td>0.329309</td>\n",
       "      <td>0.651901</td>\n",
       "      <td>0.310710</td>\n",
       "      <td>0.537525</td>\n",
       "      <td>0.436034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014860</td>\n",
       "      <td>0.015185</td>\n",
       "      <td>-0.122630</td>\n",
       "      <td>-0.105123</td>\n",
       "      <td>0.022949</td>\n",
       "      <td>-0.022683</td>\n",
       "      <td>-0.287023</td>\n",
       "      <td>-0.434515</td>\n",
       "      <td>-0.242776</td>\n",
       "      <td>-0.385776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.495077</td>\n",
       "      <td>0.592108</td>\n",
       "      <td>0.399682</td>\n",
       "      <td>0.647337</td>\n",
       "      <td>0.329309</td>\n",
       "      <td>0.651901</td>\n",
       "      <td>0.310710</td>\n",
       "      <td>0.537525</td>\n",
       "      <td>0.436034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014860</td>\n",
       "      <td>0.015185</td>\n",
       "      <td>-0.122630</td>\n",
       "      <td>-0.105123</td>\n",
       "      <td>0.022949</td>\n",
       "      <td>-0.022683</td>\n",
       "      <td>-0.287023</td>\n",
       "      <td>-0.434515</td>\n",
       "      <td>-0.242776</td>\n",
       "      <td>-0.385776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.493193</td>\n",
       "      <td>0.595036</td>\n",
       "      <td>0.408497</td>\n",
       "      <td>0.678957</td>\n",
       "      <td>0.333286</td>\n",
       "      <td>0.661445</td>\n",
       "      <td>0.311194</td>\n",
       "      <td>0.553189</td>\n",
       "      <td>0.450343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037487</td>\n",
       "      <td>-0.021422</td>\n",
       "      <td>-0.183644</td>\n",
       "      <td>-0.139331</td>\n",
       "      <td>0.013685</td>\n",
       "      <td>-0.013566</td>\n",
       "      <td>-0.136108</td>\n",
       "      <td>-0.406317</td>\n",
       "      <td>0.093499</td>\n",
       "      <td>-0.230269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.492759</td>\n",
       "      <td>0.595715</td>\n",
       "      <td>0.412542</td>\n",
       "      <td>0.680569</td>\n",
       "      <td>0.338718</td>\n",
       "      <td>0.664453</td>\n",
       "      <td>0.312522</td>\n",
       "      <td>0.554868</td>\n",
       "      <td>0.456708</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043242</td>\n",
       "      <td>-0.012215</td>\n",
       "      <td>-0.169574</td>\n",
       "      <td>-0.093957</td>\n",
       "      <td>0.014683</td>\n",
       "      <td>-0.014548</td>\n",
       "      <td>-0.033808</td>\n",
       "      <td>-0.260285</td>\n",
       "      <td>0.177826</td>\n",
       "      <td>-0.076468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.492311</td>\n",
       "      <td>0.596074</td>\n",
       "      <td>0.411140</td>\n",
       "      <td>0.677054</td>\n",
       "      <td>0.339470</td>\n",
       "      <td>0.664882</td>\n",
       "      <td>0.313429</td>\n",
       "      <td>0.554650</td>\n",
       "      <td>0.455327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087922</td>\n",
       "      <td>0.113832</td>\n",
       "      <td>-0.044071</td>\n",
       "      <td>0.013093</td>\n",
       "      <td>0.016334</td>\n",
       "      <td>-0.016176</td>\n",
       "      <td>-0.094358</td>\n",
       "      <td>-0.319006</td>\n",
       "      <td>0.029275</td>\n",
       "      <td>-0.234655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>286.0</td>\n",
       "      <td>0.342838</td>\n",
       "      <td>0.469944</td>\n",
       "      <td>0.267143</td>\n",
       "      <td>0.603506</td>\n",
       "      <td>0.223710</td>\n",
       "      <td>0.589624</td>\n",
       "      <td>0.249557</td>\n",
       "      <td>0.485274</td>\n",
       "      <td>0.371051</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009098</td>\n",
       "      <td>0.022492</td>\n",
       "      <td>-0.133869</td>\n",
       "      <td>-0.081422</td>\n",
       "      <td>0.007985</td>\n",
       "      <td>-0.008246</td>\n",
       "      <td>-0.297894</td>\n",
       "      <td>-0.145936</td>\n",
       "      <td>-0.186450</td>\n",
       "      <td>0.125205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>289.0</td>\n",
       "      <td>0.342838</td>\n",
       "      <td>0.469944</td>\n",
       "      <td>0.267143</td>\n",
       "      <td>0.603506</td>\n",
       "      <td>0.223710</td>\n",
       "      <td>0.589624</td>\n",
       "      <td>0.249557</td>\n",
       "      <td>0.485274</td>\n",
       "      <td>0.371051</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009098</td>\n",
       "      <td>0.022492</td>\n",
       "      <td>-0.133869</td>\n",
       "      <td>-0.081422</td>\n",
       "      <td>0.007985</td>\n",
       "      <td>-0.008246</td>\n",
       "      <td>-0.297894</td>\n",
       "      <td>-0.145936</td>\n",
       "      <td>-0.186450</td>\n",
       "      <td>0.125205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>292.0</td>\n",
       "      <td>0.342838</td>\n",
       "      <td>0.469944</td>\n",
       "      <td>0.267143</td>\n",
       "      <td>0.603506</td>\n",
       "      <td>0.223710</td>\n",
       "      <td>0.589624</td>\n",
       "      <td>0.249557</td>\n",
       "      <td>0.485274</td>\n",
       "      <td>0.371051</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009098</td>\n",
       "      <td>0.022492</td>\n",
       "      <td>-0.133869</td>\n",
       "      <td>-0.081422</td>\n",
       "      <td>0.007985</td>\n",
       "      <td>-0.008246</td>\n",
       "      <td>-0.297894</td>\n",
       "      <td>-0.145936</td>\n",
       "      <td>-0.186450</td>\n",
       "      <td>0.125205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>295.0</td>\n",
       "      <td>0.342838</td>\n",
       "      <td>0.469944</td>\n",
       "      <td>0.267143</td>\n",
       "      <td>0.603506</td>\n",
       "      <td>0.223710</td>\n",
       "      <td>0.589624</td>\n",
       "      <td>0.249557</td>\n",
       "      <td>0.485274</td>\n",
       "      <td>0.371051</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009098</td>\n",
       "      <td>0.022492</td>\n",
       "      <td>-0.133869</td>\n",
       "      <td>-0.081422</td>\n",
       "      <td>0.007985</td>\n",
       "      <td>-0.008246</td>\n",
       "      <td>-0.297894</td>\n",
       "      <td>-0.145936</td>\n",
       "      <td>-0.186450</td>\n",
       "      <td>0.125205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>298.0</td>\n",
       "      <td>0.342838</td>\n",
       "      <td>0.469944</td>\n",
       "      <td>0.267143</td>\n",
       "      <td>0.603506</td>\n",
       "      <td>0.223710</td>\n",
       "      <td>0.589624</td>\n",
       "      <td>0.249557</td>\n",
       "      <td>0.485274</td>\n",
       "      <td>0.371051</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009098</td>\n",
       "      <td>0.022492</td>\n",
       "      <td>-0.133869</td>\n",
       "      <td>-0.081422</td>\n",
       "      <td>0.007985</td>\n",
       "      <td>-0.008246</td>\n",
       "      <td>-0.297894</td>\n",
       "      <td>-0.145936</td>\n",
       "      <td>-0.186450</td>\n",
       "      <td>0.125205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     frame       x_0      x_11      x_12      x_13      x_14      x_15  \\\n",
       "0      1.0  0.495077  0.592108  0.399682  0.647337  0.329309  0.651901   \n",
       "1      3.0  0.495077  0.592108  0.399682  0.647337  0.329309  0.651901   \n",
       "2      4.0  0.493193  0.595036  0.408497  0.678957  0.333286  0.661445   \n",
       "3      5.0  0.492759  0.595715  0.412542  0.680569  0.338718  0.664453   \n",
       "4      6.0  0.492311  0.596074  0.411140  0.677054  0.339470  0.664882   \n",
       "..     ...       ...       ...       ...       ...       ...       ...   \n",
       "171  286.0  0.342838  0.469944  0.267143  0.603506  0.223710  0.589624   \n",
       "172  289.0  0.342838  0.469944  0.267143  0.603506  0.223710  0.589624   \n",
       "173  292.0  0.342838  0.469944  0.267143  0.603506  0.223710  0.589624   \n",
       "174  295.0  0.342838  0.469944  0.267143  0.603506  0.223710  0.589624   \n",
       "175  298.0  0.342838  0.469944  0.267143  0.603506  0.223710  0.589624   \n",
       "\n",
       "         x_16      x_23      x_24  ...      z_13      z_14      z_15  \\\n",
       "0    0.310710  0.537525  0.436034  ...  0.014860  0.015185 -0.122630   \n",
       "1    0.310710  0.537525  0.436034  ...  0.014860  0.015185 -0.122630   \n",
       "2    0.311194  0.553189  0.450343  ... -0.037487 -0.021422 -0.183644   \n",
       "3    0.312522  0.554868  0.456708  ... -0.043242 -0.012215 -0.169574   \n",
       "4    0.313429  0.554650  0.455327  ...  0.087922  0.113832 -0.044071   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "171  0.249557  0.485274  0.371051  ... -0.009098  0.022492 -0.133869   \n",
       "172  0.249557  0.485274  0.371051  ... -0.009098  0.022492 -0.133869   \n",
       "173  0.249557  0.485274  0.371051  ... -0.009098  0.022492 -0.133869   \n",
       "174  0.249557  0.485274  0.371051  ... -0.009098  0.022492 -0.133869   \n",
       "175  0.249557  0.485274  0.371051  ... -0.009098  0.022492 -0.133869   \n",
       "\n",
       "         z_16      z_23      z_24      z_25      z_26      z_29      z_30  \n",
       "0   -0.105123  0.022949 -0.022683 -0.287023 -0.434515 -0.242776 -0.385776  \n",
       "1   -0.105123  0.022949 -0.022683 -0.287023 -0.434515 -0.242776 -0.385776  \n",
       "2   -0.139331  0.013685 -0.013566 -0.136108 -0.406317  0.093499 -0.230269  \n",
       "3   -0.093957  0.014683 -0.014548 -0.033808 -0.260285  0.177826 -0.076468  \n",
       "4    0.013093  0.016334 -0.016176 -0.094358 -0.319006  0.029275 -0.234655  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "171 -0.081422  0.007985 -0.008246 -0.297894 -0.145936 -0.186450  0.125205  \n",
       "172 -0.081422  0.007985 -0.008246 -0.297894 -0.145936 -0.186450  0.125205  \n",
       "173 -0.081422  0.007985 -0.008246 -0.297894 -0.145936 -0.186450  0.125205  \n",
       "174 -0.081422  0.007985 -0.008246 -0.297894 -0.145936 -0.186450  0.125205  \n",
       "175 -0.081422  0.007985 -0.008246 -0.297894 -0.145936 -0.186450  0.125205  \n",
       "\n",
       "[176 rows x 40 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frame 오름차순, source_index 우선 정렬\n",
    "test_video = test_video.sort_values(by=[\"frame\"])\n",
    "\n",
    "# 피벗: (frame, source_index) 기준, landmark_id 별 x/y/z를 칼럼으로\n",
    "df_pivot = test_video.pivot(index=[\"frame\"], columns=\"landmark_id\", values=[\"x\", \"y\", \"z\"])\n",
    "\n",
    "# 다중 인덱스 컬럼을 단일 열로 변환: ex) ('x', 11.0) -> x_11\n",
    "df_pivot.columns = [f\"{coord}_{int(lid)}\" for coord, lid in df_pivot.columns]\n",
    "\n",
    "# 인덱스 복구\n",
    "df_pivot.reset_index(inplace=True)\n",
    "                     \n",
    "# 다시 source_index 기준으로 묶고, 그 안에서 frame 오름차순 정렬 (보장용)\n",
    "df_pivot = df_pivot.sort_values(by=[\"frame\"]).reset_index(drop=True)\n",
    "\n",
    "df_pivot\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1cb82fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PNC\\AppData\\Local\\Temp\\ipykernel_23976\\2943254839.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('./Final_model/GRU(64, 97.6%, 100frames).pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = fall_detect_model\n",
    "\n",
    "# 2. 그런 다음 state_dict를 로드합니다\n",
    "model.load_state_dict(torch.load('./Final_model/GRU(64, 97.6%, 100frames).pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e9a75f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.tensor(df_pivot.values, dtype=torch.float32).to(DEVICE)\n",
    "X_tensor = X_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7290fda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0056]], device='cuda:0')\n",
      "예측 결과: tensor([[0]], device='cuda:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "fall_detect_model.eval()\n",
    "with torch.no_grad():\n",
    "    output = fall_detect_model(X_tensor)  # 출력: (batch_size, 1)\n",
    "    probs = torch.sigmoid(output)         # 확률화\n",
    "    predicted_classes = (probs > 0.5).int()  # 0 또는 1로 변환\n",
    "print(probs)\n",
    "print(\"예측 결과:\", predicted_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c239f65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to('cpu')  # 디바이스 일치\n",
    "\n",
    "example_input = torch.randn(1, 100, 40)\n",
    "traced_model = torch.jit.trace(model, example_input)\n",
    "traced_model.save(\"./Final_model/model_script(64).pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e92bdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%self.1 : __torch__.FallDetectModel,\n",
      "      %inputs : Float(1, 100, 40, strides=[4000, 40, 1], requires_grad=0, device=cpu)):\n",
      "  %output : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"output\"](%self.1)\n",
      "  %model : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"model\"](%self.1)\n",
      "  %109 : Tensor = prim::CallMethod[name=\"forward\"](%model, %inputs)\n",
      "  %71 : int = prim::Constant[value=0]() # C:\\Users\\PNC\\AppData\\Local\\Temp\\ipykernel_23976\\20476242.py:23:0\n",
      "  %72 : int = prim::Constant[value=0]() # C:\\Users\\PNC\\AppData\\Local\\Temp\\ipykernel_23976\\20476242.py:23:0\n",
      "  %73 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\PNC\\AppData\\Local\\Temp\\ipykernel_23976\\20476242.py:23:0\n",
      "  %74 : int = prim::Constant[value=1]() # C:\\Users\\PNC\\AppData\\Local\\Temp\\ipykernel_23976\\20476242.py:23:0\n",
      "  %75 : Float(1, 100, 128, strides=[128, 128, 1], requires_grad=1, device=cpu) = aten::slice(%109, %71, %72, %73, %74) # C:\\Users\\PNC\\AppData\\Local\\Temp\\ipykernel_23976\\20476242.py:23:0\n",
      "  %76 : int = prim::Constant[value=1]() # C:\\Users\\PNC\\AppData\\Local\\Temp\\ipykernel_23976\\20476242.py:23:0\n",
      "  %77 : int = prim::Constant[value=-1]() # C:\\Users\\PNC\\AppData\\Local\\Temp\\ipykernel_23976\\20476242.py:23:0\n",
      "  %78 : Float(1, 128, strides=[128, 1], requires_grad=1, device=cpu) = aten::select(%75, %76, %77) # C:\\Users\\PNC\\AppData\\Local\\Temp\\ipykernel_23976\\20476242.py:23:0\n",
      "  %79 : int = prim::Constant[value=1]() # C:\\Users\\PNC\\AppData\\Local\\Temp\\ipykernel_23976\\20476242.py:23:0\n",
      "  %80 : int = prim::Constant[value=0]() # C:\\Users\\PNC\\AppData\\Local\\Temp\\ipykernel_23976\\20476242.py:23:0\n",
      "  %81 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\PNC\\AppData\\Local\\Temp\\ipykernel_23976\\20476242.py:23:0\n",
      "  %82 : int = prim::Constant[value=1]() # C:\\Users\\PNC\\AppData\\Local\\Temp\\ipykernel_23976\\20476242.py:23:0\n",
      "  %input : Float(1, 128, strides=[128, 1], requires_grad=1, device=cpu) = aten::slice(%78, %79, %80, %81, %82) # C:\\Users\\PNC\\AppData\\Local\\Temp\\ipykernel_23976\\20476242.py:23:0\n",
      "  %110 : Tensor = prim::CallMethod[name=\"forward\"](%output, %input)\n",
      "  return (%110)\n",
      "\n",
      "def forward(self,\n",
      "    inputs: Tensor) -> Tensor:\n",
      "  output = self.output\n",
      "  model = self.model\n",
      "  _0 = torch.slice((model).forward(inputs, ), 0, 0, 9223372036854775807)\n",
      "  input = torch.slice(torch.select(_0, 1, -1), 1, 0, 9223372036854775807)\n",
      "  return (output).forward(input, )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(traced_model.graph)\n",
    "print(traced_model.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f5e3472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0056]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor = X_tensor.to('cpu')\n",
    "\n",
    "torch.sigmoid(traced_model(X_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067b89c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
